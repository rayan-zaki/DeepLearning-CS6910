{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ebc9da6",
   "metadata": {},
   "source": [
    "## Configuration Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86d8a56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "module = 'GRU'\n",
    "epochs = 20\n",
    "optim_name = 'adam'\n",
    "learning_rate = 1e-3\n",
    "CLIP = 1\n",
    "teacher_forcing_ratio = 0.5\n",
    "beam_width = 2\n",
    "no_encoder_decoder_layers = 3\n",
    "hidden_layer_size = 256\n",
    "dropout = 0.5\n",
    "enc_embedding_dim = 0\n",
    "dec_embedding_dim = 0\n",
    "attention = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be9c551",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "844505c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data_utils\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "from util import *\n",
    "\n",
    "import operator\n",
    "from queue import PriorityQueue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a4e6c4",
   "metadata": {},
   "source": [
    "## Set up device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "452620f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a0a185",
   "metadata": {},
   "source": [
    "## Model name and create directory for checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d95a9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = 'Best_Dakshina_Hi_enc_dec'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5874b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "    os.makedirs(modelName+\"/checkpoint\")\n",
    "    os.makedirs(modelName+\"/best_model\")\n",
    "except:\n",
    "    print(\"directory already present\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ece13e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckp_path = \"./\"+modelName+\"/checkpoint/current_checkpoint.pt\"\n",
    "best_ckp_path = \"./\"+modelName+\"/best_model/best_model.pt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5efd8c",
   "metadata": {},
   "source": [
    "## Set up wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90f26d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: rayanz (use `wandb login --relogin` to force relogin)\n",
      "wandb: wandb version 0.10.30 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.22<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">comic-bird-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/rayanz/Best_Dakshina_Hi_enc_dec\" target=\"_blank\">https://wandb.ai/rayanz/Best_Dakshina_Hi_enc_dec</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/rayanz/Best_Dakshina_Hi_enc_dec/runs/1prriobz\" target=\"_blank\">https://wandb.ai/rayanz/Best_Dakshina_Hi_enc_dec/runs/1prriobz</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\Rayan Zaki\\Desktop\\Fundamentals of Deep Learning\\Assignment 3\\Practice\\Level 1\\wandb\\run-20210516_151415-1prriobz</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1>Run(1prriobz)</h1><iframe src=\"https://wandb.ai/rayanz/Best_Dakshina_Hi_enc_dec/runs/1prriobz\" style=\"border:none;width:100%;height:400px\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x22e1a1a53c8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.init(project=modelName)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e25dba3",
   "metadata": {},
   "source": [
    "## Set up Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4fcc57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users/Rayan Zaki/Downloads/dakshina_dataset_v1.0/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.train.tsv\", 'r', encoding=\"utf8\") as f:\n",
    "    train_lines = f.read().split(\"\\n\")\n",
    "    \n",
    "with open(r\"C:\\Users/Rayan Zaki/Downloads/dakshina_dataset_v1.0/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.dev.tsv\", 'r', encoding=\"utf8\") as f:\n",
    "    val_lines = f.read().split(\"\\n\")\n",
    "    \n",
    "with open(r\"C:\\Users/Rayan Zaki/Downloads/dakshina_dataset_v1.0/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.test.tsv\", 'r', encoding=\"utf8\") as f:\n",
    "    test_lines = f.read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12af2065",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_num_samples = len(train_lines)\n",
    "val_num_samples = len(val_lines)\n",
    "test_num_samples = len(test_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0da68eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_texts = []\n",
    "train_target_texts = []\n",
    "\n",
    "val_input_texts = []\n",
    "val_target_texts = []\n",
    "\n",
    "test_input_texts = []\n",
    "test_target_texts = []\n",
    "\n",
    "input_characters = set()\n",
    "target_characters = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6aa5511b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train samples: 44204\n",
      "Number of unique input tokens: 27\n",
      "Number of unique output tokens: 66\n",
      "Max train sequence length for inputs: 20\n",
      "Max train sequence length for outputs: 21\n"
     ]
    }
   ],
   "source": [
    "## Train Data ##\n",
    "\n",
    "for line in train_lines[: min(train_num_samples, len(train_lines) - 1)]:\n",
    "    target_text, input_text, _ = line.split(\"\\t\")\n",
    "    target_text = \"\\t\" + target_text + \"\\n\"\n",
    "    train_input_texts.append(input_text)\n",
    "    train_target_texts.append(target_text)\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n",
    "\n",
    "input_characters.add(' ')\n",
    "target_characters.add(' ')\n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "\n",
    "train_max_encoder_seq_length = max([len(txt) for txt in train_input_texts])\n",
    "train_max_decoder_seq_length = max([len(txt) for txt in train_target_texts])\n",
    "\n",
    "print(\"Number of train samples:\", len(train_input_texts))\n",
    "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
    "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
    "\n",
    "print(\"Max train sequence length for inputs:\", train_max_encoder_seq_length)\n",
    "print(\"Max train sequence length for outputs:\", train_max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fe62ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of val samples: 4358\n",
      "Max val sequence length for inputs: 18\n",
      "Max val sequence length for outputs: 16\n"
     ]
    }
   ],
   "source": [
    "## Val Data ##\n",
    "\n",
    "for line in val_lines[: min(val_num_samples, len(val_lines) - 1)]:\n",
    "    target_text, input_text, _ = line.split(\"\\t\")\n",
    "    target_text = \"\\t\" + target_text + \"\\n\"\n",
    "    val_input_texts.append(input_text)\n",
    "    val_target_texts.append(target_text)\n",
    "    \n",
    "val_max_encoder_seq_length = max([len(txt) for txt in val_input_texts])\n",
    "val_max_decoder_seq_length = max([len(txt) for txt in val_target_texts])\n",
    "\n",
    "print(\"Number of val samples:\", len(val_input_texts))\n",
    "\n",
    "print(\"Max val sequence length for inputs:\", val_max_encoder_seq_length)\n",
    "print(\"Max val sequence length for outputs:\", val_max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bbca9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test samples: 4502\n",
      "Max test sequence length for inputs: 16\n",
      "Max test sequence length for outputs: 17\n"
     ]
    }
   ],
   "source": [
    "## Test Data ##\n",
    "\n",
    "for line in test_lines[: min(test_num_samples, len(test_lines) - 1)]:\n",
    "    target_text, input_text, _ = line.split(\"\\t\")\n",
    "    target_text = \"\\t\" + target_text + \"\\n\"\n",
    "    test_input_texts.append(input_text)\n",
    "    test_target_texts.append(target_text)\n",
    "    \n",
    "test_max_encoder_seq_length = max([len(txt) for txt in test_input_texts])\n",
    "test_max_decoder_seq_length = max([len(txt) for txt in test_target_texts])\n",
    "\n",
    "print(\"Number of test samples:\", len(test_input_texts))\n",
    "\n",
    "print(\"Max test sequence length for inputs:\", test_max_encoder_seq_length)\n",
    "print(\"Max test sequence length for outputs:\", test_max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c2fb4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# token indices\n",
    "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
    "\n",
    "# Train data\n",
    "encoder_input_data_train = np.zeros(\n",
    "    (len(train_input_texts), train_max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\"\n",
    ")\n",
    "decoder_input_data_train = np.zeros(\n",
    "    (len(train_input_texts), train_max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
    ")\n",
    "\n",
    "# Val data\n",
    "encoder_input_data_val = np.zeros(\n",
    "    (len(val_input_texts), train_max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\"\n",
    ")\n",
    "decoder_input_data_val = np.zeros(\n",
    "    (len(val_input_texts), train_max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
    ")\n",
    "\n",
    "# Test data\n",
    "encoder_input_data_test = np.zeros(\n",
    "    (len(test_input_texts), train_max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\"\n",
    ")\n",
    "decoder_input_data_test = np.zeros(\n",
    "    (len(test_input_texts), train_max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "755765e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train Data ##\n",
    "\n",
    "for i, (input_text, target_text) in enumerate(zip(train_input_texts, train_target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data_train[i, t, input_token_index[char]] = 1. \n",
    "    encoder_input_data_train[i, t + 1:, input_token_index[' ']] = 1.\n",
    "    \n",
    "    for t, char in enumerate(target_text):\n",
    "        decoder_input_data_train[i, t, target_token_index[char]] = 1.\n",
    "    decoder_input_data_train[i, t + 1:, target_token_index[' ']] = 1.\n",
    "    \n",
    "## Val Data ##\n",
    "\n",
    "for i, (input_text, target_text) in enumerate(zip(val_input_texts, val_target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data_val[i, t, input_token_index[char]] = 1. \n",
    "    encoder_input_data_val[i, t + 1:, input_token_index[' ']] = 1.\n",
    "    \n",
    "    for t, char in enumerate(target_text):\n",
    "        decoder_input_data_val[i, t, target_token_index[char]] = 1.\n",
    "    decoder_input_data_val[i, t + 1:, target_token_index[' ']] = 1.\n",
    "    \n",
    "## Test Data ##\n",
    "\n",
    "for i, (input_text, target_text) in enumerate(zip(test_input_texts, test_target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data_test[i, t, input_token_index[char]] = 1. \n",
    "    encoder_input_data_test[i, t + 1:, input_token_index[' ']] = 1.\n",
    "    \n",
    "    for t, char in enumerate(target_text):\n",
    "        decoder_input_data_test[i, t, target_token_index[char]] = 1.\n",
    "    decoder_input_data_test[i, t + 1:, target_token_index[' ']] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebffc224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to tensors so that u can pass through dataloaders\n",
    "\n",
    "encoder_inp_train = torch.stack([torch.from_numpy(np.array(i)) for i in encoder_input_data_train])\n",
    "decoder_inp_train = torch.stack([torch.from_numpy(np.array(i)) for i in decoder_input_data_train])\n",
    "\n",
    "encoder_inp_val = torch.stack([torch.from_numpy(np.array(i)) for i in encoder_input_data_val])\n",
    "decoder_inp_val = torch.stack([torch.from_numpy(np.array(i)) for i in decoder_input_data_val])\n",
    "\n",
    "encoder_inp_test = torch.stack([torch.from_numpy(np.array(i)) for i in encoder_input_data_test])\n",
    "decoder_inp_test = torch.stack([torch.from_numpy(np.array(i)) for i in decoder_input_data_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47a4ae78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_size = 64\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(encoder_inp_train, decoder_inp_train)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle = True)\n",
    "\n",
    "val_dataset = torch.utils.data.TensorDataset(encoder_inp_val, decoder_inp_val)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size)#, shuffle = True)\n",
    "\n",
    "test_dataset = torch.utils.data.TensorDataset(encoder_inp_test, decoder_inp_test)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)#, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c20593",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de4135b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(Attention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "        self.v = nn.Parameter(torch.rand(hidden_size))\n",
    "        stdv = 1. / math.sqrt(self.v.size(0))\n",
    "        self.v.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        timestep = encoder_outputs.size(0)\n",
    "        h = hidden.repeat(timestep, 1, 1).transpose(0, 1)\n",
    "        encoder_outputs = encoder_outputs.transpose(0, 1)\n",
    "        attn_energies = self.score(h, encoder_outputs) \n",
    "        return F.softmax(attn_energies, dim=1).unsqueeze(1) \n",
    "\n",
    "    def score(self, hidden, encoder_outputs):\n",
    "        energy = F.relu(self.attn(torch.cat([hidden, encoder_outputs], 2)))\n",
    "        energy = energy.transpose(1, 2)\n",
    "        v = self.v.repeat(encoder_outputs.size(0), 1).unsqueeze(1)\n",
    "        energy = torch.bmm(v, energy)\n",
    "        return energy.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a8a7067",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,  num_encoder_tokens, hid_dim, n_layers, dropout, enc_embedding_dim = 0, module='LSTM'):\n",
    "        super(Encoder,self).__init__()\n",
    "        \n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.module = module\n",
    "        self.embedding_dim = enc_embedding_dim\n",
    "        self.enc_inp = num_encoder_tokens\n",
    "        if self.embedding_dim !=0:\n",
    "            self.enc_inp = self.embedding_dim\n",
    "            self.embedding = nn.Embedding(num_encoder_tokens, self.embedding_dim)\n",
    "            \n",
    "        if self.module =='LSTM':\n",
    "            self.rnn = nn.LSTM(self.enc_inp, hid_dim, n_layers, dropout = dropout)\n",
    "        elif self.module == 'RNN':\n",
    "            self.rnn = nn.RNN(self.enc_inp, hid_dim, n_layers, dropout = dropout)\n",
    "        elif self.module == 'GRU':\n",
    "            self.rnn = nn.GRU(self.enc_inp, hid_dim, n_layers, dropout = dropout)\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        \n",
    "        inp = inp.transpose(0,1)  # check input dimensions before embedding. Currently : (T, N)\n",
    "        if self.embedding_dim !=0:\n",
    "            inp = inp.argmax(2)\n",
    "            inp = self.embedding(inp)\n",
    "            \n",
    "        outputs, hidden_cell = self.rnn(inp)\n",
    "        \n",
    "        return outputs, hidden_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "046c4f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, num_decoder_tokens, hid_dim, n_layers, dropout, dec_embedding_dim = 0, module='LSTM', atten=False):\n",
    "        super(Decoder,self).__init__()\n",
    "        \n",
    "        self.output_dim = num_decoder_tokens\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.module = module\n",
    "        self.atten = atten\n",
    "        self.embedding_dim = dec_embedding_dim\n",
    "        self.dec_inp = num_decoder_tokens\n",
    "        \n",
    "        if self.embedding_dim !=0:\n",
    "            self.dec_inp = self.embedding_dim\n",
    "            self.embedding = nn.Embedding(num_decoder_tokens, self.embedding_dim)\n",
    "        \n",
    "        if self.atten == False:\n",
    "            if module=='LSTM':\n",
    "                self.rnn = nn.LSTM(self.dec_inp, hid_dim, n_layers, dropout = dropout)\n",
    "            if module=='RNN':\n",
    "                self.rnn = nn.RNN(self.dec_inp, hid_dim, n_layers, dropout = dropout)\n",
    "            if module=='GRU':\n",
    "                self.rnn = nn.GRU(self.dec_inp, hid_dim, n_layers, dropout = dropout)\n",
    "                \n",
    "            self.fc_out = nn.Linear(self.hid_dim, self.output_dim)\n",
    "                \n",
    "        else:\n",
    "            self.attention = Attention(self.hid_dim)\n",
    "            \n",
    "            if module=='LSTM':\n",
    "                self.rnn = nn.LSTM(self.hid_dim + self.dec_inp, hid_dim, n_layers, dropout = dropout)\n",
    "            if module=='RNN':\n",
    "                self.rnn = nn.RNN(self.hid_dim + self.dec_inp, hid_dim, n_layers, dropout = dropout)\n",
    "            if module=='GRU':\n",
    "                self.rnn = nn.GRU(self.hid_dim + self.dec_inp, hid_dim, n_layers, dropout = dropout)\n",
    "                \n",
    "            self.fc_out = nn.Linear(self.hid_dim * 2, self.output_dim)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, inp, hidden_cell, encoder_states):\n",
    "        \n",
    "        if isinstance(hidden_cell, tuple):\n",
    "            hidden = hidden_cell[0]\n",
    "            cell = hidden_cell[1]\n",
    "        else:\n",
    "            hidden = hidden_cell\n",
    "        \n",
    "        if self.embedding_dim !=0:\n",
    "            inp = inp.argmax(2)\n",
    "            inp = self.embedding(inp)\n",
    "        \n",
    "        if self.atten == False:\n",
    "            if self.module == 'LSTM':\n",
    "                output, hidden = self.rnn(inp, (hidden, cell))\n",
    "            else:\n",
    "                output, hidden = self.rnn(inp,hidden)\n",
    "\n",
    "            prediction = self.fc_out(output.squeeze(0))\n",
    "            return prediction, hidden\n",
    "        \n",
    "        else:\n",
    "            attn_weights = self.attention(hidden[-1], encoder_states)  # why -1 ? wat is dim of hidden?\n",
    "            context = attn_weights.bmm(encoder_states.transpose(0, 1))\n",
    "            context = context.transpose(0, 1)\n",
    "            rnn_inp = torch.cat([inp, context], 2) \n",
    "            \n",
    "            if self.module == 'LSTM':\n",
    "                output, hidden = self.rnn(rnn_inp, (hidden, cell))\n",
    "            else:\n",
    "                output, hidden = self.rnn(rnn_inp, hidden)\n",
    "            \n",
    "            output = output.squeeze(0) \n",
    "            context = context.squeeze(0)\n",
    "            output = self.fc_out(torch.cat([output, context], 1))\n",
    "            \n",
    "            return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3eddbe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        self.atten = self.decoder.atten\n",
    "        \n",
    "        assert encoder.hid_dim == decoder.hid_dim, \\\n",
    "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "        assert encoder.n_layers == decoder.n_layers, \\\n",
    "            \"Encoder and decoder must have equal number of layers!\"\n",
    "        \n",
    "    def forward(self, src, trg, to_train, teacher_forcing_ratio = 0.5, beam_width = 3):\n",
    "        \n",
    "        if to_train == True:\n",
    "        \n",
    "            trg = trg.transpose(0,1)\n",
    "            batch_size = trg.shape[1]\n",
    "            trg_len = trg.shape[0]\n",
    "            trg_vocab_size = self.decoder.output_dim\n",
    "            \n",
    "            outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "\n",
    "            enc_output, hidden_cell = self.encoder(src)\n",
    "            inp = trg[0,:]\n",
    "\n",
    "            for t in range(1, trg_len):\n",
    "                \n",
    "                if self.atten == False:\n",
    "                    prediction, hidden_cell = self.decoder(inp.unsqueeze(0), hidden_cell, enc_output) # recursively set hidden, cell\n",
    "                else:\n",
    "                    prediction, hidden_cell, atten_weights = self.decoder(inp.unsqueeze(0), hidden_cell, enc_output)\n",
    "                outputs[t] = prediction\n",
    "                teacher_force = random.random() < teacher_forcing_ratio\n",
    "                top1 = prediction.argmax(1)\n",
    "                top1_one_hot = torch.zeros_like(prediction).to(self.device)\n",
    "                top1_one_hot[:,top1] = 1.\n",
    "\n",
    "                inp = trg[t] if teacher_force else top1_one_hot\n",
    "\n",
    "            return outputs\n",
    "        \n",
    "        else :\n",
    "            batch_size = trg.shape[0]\n",
    "            trg_len = trg.shape[1]\n",
    "            trg_vocab_size = self.decoder.output_dim\n",
    "\n",
    "            enc_output, hidden_cell = self.encoder(src)\n",
    "            outputs = self.beam_decode(beam_width, trg, hidden_cell, enc_output)\n",
    "            \n",
    "            return outputs\n",
    "        \n",
    "    def beam_decode(self, beam_width, target_tensor, decoder_hiddens, encoder_outputs=None):\n",
    "        \n",
    "        target_tensor = target_tensor.transpose(0,1)\n",
    "        beam_width = beam_width\n",
    "        topk = 1\n",
    "        decoded_batch = []\n",
    "        \n",
    "        batch_loss = []\n",
    "        EOS_token = target_token_index['\\n']\n",
    "        \n",
    "        criterion_infer = torch.nn.CrossEntropyLoss(ignore_index = target_token_index[' '])\n",
    "        \n",
    "        for idx in range(target_tensor.size(1)):\n",
    "            if isinstance(decoder_hiddens, tuple):\n",
    "                decoder_hidden = (\n",
    "                    decoder_hiddens[0][:, idx, :].contiguous().unsqueeze(1), decoder_hiddens[1][:, idx, :].contiguous().unsqueeze(1))\n",
    "            else:\n",
    "                decoder_hidden = decoder_hiddens[:, idx, :].contiguous().unsqueeze(1)\n",
    "                \n",
    "            encoder_output = encoder_outputs[:, idx, :].unsqueeze(1)\n",
    "            decoder_input_token =  target_token_index[\"\\t\"]\n",
    "            endnodes = []\n",
    "            number_required = min((topk + 1), topk - len(endnodes))\n",
    "\n",
    "            node = BeamSearchNode(decoder_hidden,   None,       decoder_input_token, 0,     1   , 0)\n",
    "            nodes = PriorityQueue()\n",
    "\n",
    "            nodes.put((-node.eval(), node))\n",
    "            qsize = 1\n",
    "\n",
    "            while True:\n",
    "                if qsize > train_max_decoder_seq_length * beam_width: \n",
    "                    break\n",
    "\n",
    "                score, n = nodes.get()\n",
    "                decoder_input_token = n.wordid\n",
    "                #print(\"wordid: \",n.wordid)\n",
    "                decoder_hidden = n.h\n",
    "                \n",
    "                decoder_input = torch.zeros((1, 1, num_decoder_tokens)).to(self.device)\n",
    "                decoder_input[0, 0, decoder_input_token] = 1.\n",
    "                if n.wordid == EOS_token and n.prevNode != None:\n",
    "                    \n",
    "                    endnodes.append((score, n))\n",
    "                    if len(endnodes) >= number_required:\n",
    "                        break\n",
    "                    else:\n",
    "                        continue\n",
    "\n",
    "                if self.atten == False:\n",
    "                    decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_output)\n",
    "                \n",
    "                else:\n",
    "                    decoder_output, decoder_hidden, atten_weights = self.decoder(decoder_input, decoder_hidden, encoder_output)\n",
    "                \n",
    "                log_softmax =  F.log_softmax(decoder_output, dim=1)\n",
    "                log_prob, indexes = torch.topk(log_softmax, beam_width)\n",
    "                #log_prob =  F.log_softmax(log_prob, dim=1)\n",
    "                nextnodes = []\n",
    "                # Below seems okay :-)\n",
    "                #print(\"Verify target_tensor shape to check argmax(0)\",target_tensor[n.leng, idx].shape)\n",
    "                loss_at_t = criterion_infer(decoder_output, target_tensor[n.leng, idx].argmax(0).unsqueeze(0))\n",
    "                \n",
    "                for new_k in range(beam_width):\n",
    "                    decoded_t = indexes[0][new_k].view(-1)\n",
    "                    log_p = log_prob[0][new_k].item()\n",
    "                    #print(\"decoded_t: \",decoded_t)\n",
    "                    #print(\"decoded_t: \",n.wordid)\n",
    "                    node = BeamSearchNode(decoder_hidden, n, decoded_t.item(), n.logp + log_p, n.leng + 1, n.loss + loss_at_t)\n",
    "                    score = -node.eval()\n",
    "                    \n",
    "                    if n.leng < train_max_decoder_seq_length - 1:\n",
    "                        nextnodes.append((score, node))\n",
    "                    \n",
    "                    else:\n",
    "                        endnodes.append((score,node))\n",
    "\n",
    "                for i in range(len(nextnodes)):\n",
    "                    score, nn = nextnodes[i]\n",
    "                    nodes.put((score, nn))\n",
    "                    \n",
    "                qsize += len(nextnodes) - 1\n",
    "            \n",
    "            if len(endnodes) == 0:\n",
    "                endnodes = [nodes.get() for _ in range(topk)]\n",
    "\n",
    "            utterances = []\n",
    "            utterances_loss = []\n",
    "            for score, n in sorted(endnodes, key=operator.itemgetter(0)):\n",
    "                utterance = []\n",
    "                utterance.append(n.wordid)\n",
    "                loss_sum = n.loss\n",
    "                utterances_loss.append(loss_sum)\n",
    "                while n.prevNode != None:\n",
    "                    n = n.prevNode\n",
    "                    utterance.append(n.wordid)\n",
    "                \n",
    "                utterance = utterance[::-1]\n",
    "                utterances.append(utterance)\n",
    "                #print(utterance)\n",
    "            decoded_batch.append(utterances)\n",
    "            batch_loss.append(utterances_loss)\n",
    "            \n",
    "        return decoded_batch, batch_loss\n",
    "\n",
    "\n",
    "class BeamSearchNode(object):\n",
    "    def __init__(self, hiddenstate, previousNode, wordId, logProb, length, loss):\n",
    "        self.h = hiddenstate\n",
    "        self.prevNode = previousNode\n",
    "        self.wordid = wordId\n",
    "        self.logp = logProb\n",
    "        self.leng = length\n",
    "        self.loss = loss\n",
    "\n",
    "    def eval(self, alpha=1.0):\n",
    "        reward = 0\n",
    "        return self.logp / float(self.leng - 1 + 1e-6) + alpha * reward \n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return self.leng < other.leng\n",
    "\n",
    "    def __gt__(self, other):\n",
    "        return self.leng > other.leng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa946f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of encoder tokens: 27\n"
     ]
    }
   ],
   "source": [
    "print(\"No of encoder tokens:\",num_encoder_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b38dfcf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of decoder tokens: 66\n"
     ]
    }
   ],
   "source": [
    "print(\"No of decoder tokens:\",num_decoder_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4257517",
   "metadata": {},
   "source": [
    "## Create Model Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac623b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = Encoder( num_encoder_tokens, hidden_layer_size, n_layers = no_encoder_decoder_layers, enc_embedding_dim = enc_embedding_dim, dropout = dropout, module = module)\n",
    "dec = Decoder( num_decoder_tokens, hidden_layer_size, n_layers = no_encoder_decoder_layers, dec_embedding_dim = dec_embedding_dim, dropout = dropout, module = module, atten = attention)\n",
    "\n",
    "model = Seq2Seq(enc, dec, device).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed14c5ea",
   "metadata": {},
   "source": [
    "## Optimizer and criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e8cf9a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = learning_rate\n",
    "if optim_name == 'adam':\n",
    "    optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "else:\n",
    "    print(\"Please declare the optimizer first\")\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = target_token_index[' '])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4373b05f",
   "metadata": {},
   "source": [
    "## Helpers to decode back sentance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4aac82c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fca3128",
   "metadata": {},
   "source": [
    "## Functions to match output sequence to calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "58094cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_correct_in_batch_train(target, output):\n",
    "    target = target.transpose(0,1)\n",
    "    truth = output.argmax(2).transpose(0,1)\n",
    "    no_correct = 0\n",
    "    batch_size = target.shape[0]\n",
    "    trgt_length = target.shape[1]\n",
    "    for seq in range(batch_size):\n",
    "        #decoded_sen = \"\"\n",
    "        for char in range(1, trgt_length):\n",
    "            if target[seq,char] == target_token_index['\\n']:\n",
    "                no_correct += 1\n",
    "                break\n",
    "            if target[seq,char] != truth[seq,char]:\n",
    "                break\n",
    "            #decoded_sen = decoded_sen + reverse_target_char_index[target[seq,char]]\n",
    "        #print(decoded_sen)\n",
    "    return no_correct, batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a2a7e372",
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_correct_in_batch_infer(target, output, return_decoded_batch = False):\n",
    "    target = target.transpose(0,1)\n",
    "    no_correct = 0\n",
    "    batch_size = target.shape[0]\n",
    "    trgt_length = target.shape[1]\n",
    "    \n",
    "    if return_decoded_batch == True:\n",
    "        decoded_batch = []\n",
    "    \n",
    "    # Verify batch_size  ------ Seems Okay\n",
    "    #print(\"In Infer, BS = 256 , TL = 21: \",target.shape)\n",
    "    #print(\"Target BS: \", batch_size)\n",
    "    #print(\"Output BS: \", len(output))\n",
    "    for seq in range(batch_size):\n",
    "        #true_sen = \"\"\n",
    "        decoded_sen = \"\"\n",
    "        flag = 0\n",
    "        for char in range(1,trgt_length):\n",
    "            if target[seq,char] == target_token_index['\\n']:\n",
    "                if flag == 0:\n",
    "                    no_correct += 1\n",
    "                break\n",
    "            if char== len(output[seq][0]):# or target[seq,char] != output[seq][0][char]:\n",
    "                break\n",
    "            if target[seq,char] != output[seq][0][char]:\n",
    "                flag = 1\n",
    "            #true_sen = true_sen + reverse_target_char_index[target[seq,char].item()]\n",
    "            decoded_sen = decoded_sen + reverse_target_char_index[output[seq][0][char]]\n",
    "            \n",
    "        if return_decoded_batch == True:\n",
    "            decoded_batch.append(decoded_sen)\n",
    "        #print(\"true output is \",true_sen)\n",
    "        #print(\"decoded output is \",decoded_sen)\n",
    "    if return_decoded_batch == True:\n",
    "        return no_correct, batch_size, decoded_batch\n",
    "    else:\n",
    "        return no_correct, batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239c9d92",
   "metadata": {},
   "source": [
    "## Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2a759b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip, teacher_forcing_ratio):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    total_no_correct = 0\n",
    "    total_samples = 0\n",
    "    for i, (src,trg) in enumerate(iterator):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        src, trg = src.to(device), trg.to(device)\n",
    "        \n",
    "        \n",
    "        output = model(src, trg, teacher_forcing_ratio = teacher_forcing_ratio, to_train = True).to(device) \n",
    "        trg = trg.transpose(0,1)\n",
    "        \n",
    "        trg = trg.argmax(2)\n",
    "        no_correct , samples = no_correct_in_batch_train(trg, output)\n",
    "        total_no_correct += no_correct\n",
    "        total_samples += samples\n",
    "        \n",
    "        output_dim = output.shape[-1]\n",
    "        \n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        trg = trg[1:].reshape(-1)\n",
    "        \n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), total_no_correct/total_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775125d9",
   "metadata": {},
   "source": [
    "## Evaluate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "560ff298",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, beam_width, return_decoded_data = False):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    total_no_correct = 0\n",
    "    total_samples = 0\n",
    "    if return_decoded_data == True:\n",
    "        decoded_data = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, (src,trg) in enumerate(iterator):\n",
    "\n",
    "            src, trg = src.to(device), trg.to(device)\n",
    "\n",
    "            output = model( src, trg, beam_width = beam_width, to_train= False)\n",
    "            \n",
    "            trg = trg.transpose(0,1)\n",
    "\n",
    "            trg = trg.argmax(2)\n",
    "            if return_decoded_data == True:\n",
    "                no_correct , samples, decoded_batch = no_correct_in_batch_infer(trg, output[0], return_decoded_batch = True)\n",
    "                \n",
    "            else:\n",
    "                no_correct , samples = no_correct_in_batch_infer(trg, output[0])\n",
    "            total_no_correct += no_correct\n",
    "            total_samples += samples\n",
    "            \n",
    "            loss = 0\n",
    "            total_chars = 0\n",
    "            for sample in range(len(output[1])):\n",
    "                for utterances in range(len(output[1][sample])):\n",
    "                    loss+= output[1][sample][utterances] \n",
    "                    total_chars += len(output[0][sample][utterances])\n",
    "            \n",
    "            epoch_loss += loss / total_chars\n",
    "            \n",
    "            if return_decoded_data == True:\n",
    "                decoded_data.extend(decoded_batch)\n",
    "    \n",
    "    if return_decoded_data == True:\n",
    "        return epoch_loss / len(iterator), total_no_correct/total_samples, decoded_data\n",
    "    \n",
    "    else:\n",
    "        return epoch_loss / len(iterator), total_no_correct/total_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fdfa45",
   "metadata": {},
   "source": [
    "## Function to calculate time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fc92fddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8aad56",
   "metadata": {},
   "source": [
    "## Start Training and evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e335a432",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate(model, train_loader,val_loader, optimizer, criterion, CLIP, N_EPOCHS, teacher_forcing_ratio, beam_width, checkpoint_path, best_model_path):\n",
    "    teacher_forcing_ratio = teacher_forcing_ratio\n",
    "    valid_loss_min = np.Inf\n",
    "    for epoch in range(N_EPOCHS):\n",
    "\n",
    "        start_time = time.time()\n",
    "        \n",
    "        train_loss, train_accuracy = train(model, train_loader, optimizer, criterion, CLIP, teacher_forcing_ratio)\n",
    "        valid_loss, valid_accuracy = evaluate(model, val_loader, beam_width)\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "        print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "        print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "        print(f'\\tTrain Accuracy: {train_accuracy:.3f}')\n",
    "        print(f'\\tVal. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
    "        print(f'\\tVal Accuracy: {valid_accuracy:.3f}')\n",
    "        \n",
    "        wandb.log({'epoch': epoch+1,'train accuracy': train_accuracy, 'val accuracy': valid_accuracy})#,\n",
    "                  #'train loss': train_loss,'train PPL':math.exp(train_loss), 'val loss': valid_loss,'valid PPL':math.exp(valid_loss)})\n",
    "        \n",
    "        \n",
    "        checkpoint = {\n",
    "            'epoch': epoch + 1,\n",
    "            'valid_loss': valid_loss,\n",
    "            'valid_acc': valid_accuracy,\n",
    "            'valid_loss_min': valid_loss_min,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }\n",
    "        \n",
    "        save_ckp(checkpoint, False, checkpoint_path, best_model_path)\n",
    "        \n",
    "        if valid_loss <= valid_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,valid_loss))\n",
    "            # save checkpoint as best model\n",
    "            save_ckp(checkpoint, True, checkpoint_path, best_model_path)\n",
    "            valid_loss_min = valid_loss\n",
    "            \n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4d17fa01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 1m 48s\n",
      "\tTrain Loss: 2.684 | Train PPL:  14.644\n",
      "\tTrain Accuracy: 0.002\n",
      "\tVal. Loss: 1.662 |  Val. PPL:   5.272\n",
      "\tVal Accuracy: 0.018\n",
      "Validation loss decreased (inf --> 1.662386).  Saving model ...\n",
      "Epoch: 02 | Time: 1m 45s\n",
      "\tTrain Loss: 1.475 | Train PPL:   4.372\n",
      "\tTrain Accuracy: 0.070\n",
      "\tVal. Loss: 1.185 |  Val. PPL:   3.270\n",
      "\tVal Accuracy: 0.196\n",
      "Validation loss decreased (1.662386 --> 1.184678).  Saving model ...\n",
      "Epoch: 03 | Time: 1m 47s\n",
      "\tTrain Loss: 1.073 | Train PPL:   2.924\n",
      "\tTrain Accuracy: 0.153\n",
      "\tVal. Loss: 1.145 |  Val. PPL:   3.142\n",
      "\tVal Accuracy: 0.271\n",
      "Validation loss decreased (1.184678 --> 1.144854).  Saving model ...\n",
      "Epoch: 04 | Time: 1m 53s\n",
      "\tTrain Loss: 0.909 | Train PPL:   2.482\n",
      "\tTrain Accuracy: 0.202\n",
      "\tVal. Loss: 1.143 |  Val. PPL:   3.137\n",
      "\tVal Accuracy: 0.302\n",
      "Validation loss decreased (1.144854 --> 1.143169).  Saving model ...\n",
      "Epoch: 05 | Time: 1m 49s\n",
      "\tTrain Loss: 0.813 | Train PPL:   2.254\n",
      "\tTrain Accuracy: 0.238\n",
      "\tVal. Loss: 1.152 |  Val. PPL:   3.166\n",
      "\tVal Accuracy: 0.324\n",
      "Epoch: 06 | Time: 1m 52s\n",
      "\tTrain Loss: 0.742 | Train PPL:   2.100\n",
      "\tTrain Accuracy: 0.268\n",
      "\tVal. Loss: 1.135 |  Val. PPL:   3.111\n",
      "\tVal Accuracy: 0.331\n",
      "Validation loss decreased (1.143169 --> 1.134905).  Saving model ...\n",
      "Epoch: 07 | Time: 1m 52s\n",
      "\tTrain Loss: 0.694 | Train PPL:   2.002\n",
      "\tTrain Accuracy: 0.290\n",
      "\tVal. Loss: 1.149 |  Val. PPL:   3.155\n",
      "\tVal Accuracy: 0.341\n",
      "Epoch: 08 | Time: 1m 53s\n",
      "\tTrain Loss: 0.655 | Train PPL:   1.926\n",
      "\tTrain Accuracy: 0.307\n",
      "\tVal. Loss: 1.139 |  Val. PPL:   3.125\n",
      "\tVal Accuracy: 0.346\n",
      "Epoch: 09 | Time: 1m 53s\n",
      "\tTrain Loss: 0.621 | Train PPL:   1.861\n",
      "\tTrain Accuracy: 0.327\n",
      "\tVal. Loss: 1.146 |  Val. PPL:   3.146\n",
      "\tVal Accuracy: 0.359\n",
      "Epoch: 10 | Time: 1m 54s\n",
      "\tTrain Loss: 0.596 | Train PPL:   1.814\n",
      "\tTrain Accuracy: 0.338\n",
      "\tVal. Loss: 1.162 |  Val. PPL:   3.195\n",
      "\tVal Accuracy: 0.364\n",
      "Epoch: 11 | Time: 1m 54s\n",
      "\tTrain Loss: 0.571 | Train PPL:   1.771\n",
      "\tTrain Accuracy: 0.358\n",
      "\tVal. Loss: 1.168 |  Val. PPL:   3.215\n",
      "\tVal Accuracy: 0.365\n",
      "Epoch: 12 | Time: 1m 55s\n",
      "\tTrain Loss: 0.550 | Train PPL:   1.733\n",
      "\tTrain Accuracy: 0.369\n",
      "\tVal. Loss: 1.203 |  Val. PPL:   3.329\n",
      "\tVal Accuracy: 0.365\n",
      "Epoch: 13 | Time: 1m 55s\n",
      "\tTrain Loss: 0.531 | Train PPL:   1.700\n",
      "\tTrain Accuracy: 0.378\n",
      "\tVal. Loss: 1.160 |  Val. PPL:   3.190\n",
      "\tVal Accuracy: 0.363\n",
      "Epoch: 14 | Time: 1m 56s\n",
      "\tTrain Loss: 0.514 | Train PPL:   1.673\n",
      "\tTrain Accuracy: 0.391\n",
      "\tVal. Loss: 1.162 |  Val. PPL:   3.198\n",
      "\tVal Accuracy: 0.370\n",
      "Epoch: 15 | Time: 1m 56s\n",
      "\tTrain Loss: 0.505 | Train PPL:   1.657\n",
      "\tTrain Accuracy: 0.399\n",
      "\tVal. Loss: 1.183 |  Val. PPL:   3.263\n",
      "\tVal Accuracy: 0.365\n",
      "Epoch: 16 | Time: 2m 0s\n",
      "\tTrain Loss: 0.487 | Train PPL:   1.627\n",
      "\tTrain Accuracy: 0.414\n",
      "\tVal. Loss: 1.197 |  Val. PPL:   3.309\n",
      "\tVal Accuracy: 0.361\n",
      "Epoch: 17 | Time: 1m 58s\n",
      "\tTrain Loss: 0.475 | Train PPL:   1.607\n",
      "\tTrain Accuracy: 0.419\n",
      "\tVal. Loss: 1.201 |  Val. PPL:   3.324\n",
      "\tVal Accuracy: 0.375\n",
      "Epoch: 18 | Time: 2m 0s\n",
      "\tTrain Loss: 0.463 | Train PPL:   1.589\n",
      "\tTrain Accuracy: 0.426\n",
      "\tVal. Loss: 1.185 |  Val. PPL:   3.272\n",
      "\tVal Accuracy: 0.377\n",
      "Epoch: 19 | Time: 1m 58s\n",
      "\tTrain Loss: 0.453 | Train PPL:   1.573\n",
      "\tTrain Accuracy: 0.433\n",
      "\tVal. Loss: 1.204 |  Val. PPL:   3.335\n",
      "\tVal Accuracy: 0.385\n",
      "Epoch: 20 | Time: 1m 58s\n",
      "\tTrain Loss: 0.441 | Train PPL:   1.555\n",
      "\tTrain Accuracy: 0.442\n",
      "\tVal. Loss: 1.186 |  Val. PPL:   3.275\n",
      "\tVal Accuracy: 0.375\n"
     ]
    }
   ],
   "source": [
    "trained_model = train_evaluate(model, \n",
    "                               train_loader, \n",
    "                               val_loader, \n",
    "                               optimizer, \n",
    "                               criterion, \n",
    "                               CLIP, \n",
    "                               epochs, \n",
    "                               teacher_forcing_ratio, \n",
    "                               beam_width,\n",
    "                               checkpoint_path = ckp_path,\n",
    "                               best_model_path = best_ckp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e5cd59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a549ee1",
   "metadata": {},
   "source": [
    "## Test accuracy for best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4afa0cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the saved last checkpoint\n",
    "best_trained_model, optimizer, start_epoch, valid_loss, valid_acc, valid_loss_min = load_ckp(best_ckp_path, model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "786c8b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_loss , infer_accuracy, decoded_data = evaluate(best_trained_model, test_loader, beam_width, return_decoded_data = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "11cda835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 0.34584629053753885\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Accuracy :\",infer_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f45074e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({\"Test Accuracy\": infer_accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bd10d278",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_inp_out = []\n",
    "for index in range(0, test_num_samples-1):\n",
    "    sample = []\n",
    "    sample.append(test_input_texts[index])\n",
    "    sample.append(decoded_data[index])\n",
    "    sample.append(test_target_texts[index][1:-1])\n",
    "    data_inp_out.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "47b16628",
   "metadata": {},
   "outputs": [],
   "source": [
    "f= open(\"predictions_vanilla.txt\",\"w+\", encoding='utf8')\n",
    "f.write(\"Input - Output - True Output\\r\")\n",
    "\n",
    "for sample in data_inp_out:\n",
    "    f.write(sample[0]+ \" - \" + sample[1] + \" - \"+ sample[2]+\" \\r\")\n",
    "    \n",
    "        \n",
    "f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "095ae3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random_indices = random.sample(range(0, test_num_samples), 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5b08b182",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_log = []\n",
    "for index in random_indices:\n",
    "    data_log.append(data_inp_out[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bdc3b241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['chadar', '', ''],\n",
       " ['diya', '', ''],\n",
       " ['kapdon', '', ''],\n",
       " ['dayitvon', '', ''],\n",
       " ['apariharya', '', ''],\n",
       " ['bachti', '', ''],\n",
       " ['aviral', '', ''],\n",
       " ['judai', '\\n', ''],\n",
       " ['sayara', '', ''],\n",
       " ['shaasakon', '', ''],\n",
       " ['ahirauli', '', ''],\n",
       " ['subhaay', '', ''],\n",
       " ['beast', '', ''],\n",
       " ['launcher', '', ''],\n",
       " ['aalochak', '', ''],\n",
       " ['ria', '', ''],\n",
       " ['around', '\\n', ''],\n",
       " ['label', '', ''],\n",
       " ['bhayo', '', ''],\n",
       " ['sunasir', '\\n', ''],\n",
       " ['pushkarna', '\\n', ''],\n",
       " ['sure', '\\n', ''],\n",
       " ['reasonal', '', ''],\n",
       " ['sapne', '', ''],\n",
       " ['tir', '', ''],\n",
       " ['uplaksh', '\\n', ''],\n",
       " ['earth', '', ''],\n",
       " ['taboo', '\\n', ''],\n",
       " ['parleron', '\\n', ''],\n",
       " ['welder', '', ''],\n",
       " ['standhari', '', ''],\n",
       " ['yda', '', ''],\n",
       " ['darmiyan', '', ''],\n",
       " ['sachidanand', '\\n', ''],\n",
       " ['swa', '', ''],\n",
       " ['chhallaa', '', ''],\n",
       " ['dharmnath', '', ''],\n",
       " ['kiratpur', '', ''],\n",
       " ['cricketer', '', ''],\n",
       " ['aapadaaaen', '', ''],\n",
       " ['jatak', '', ''],\n",
       " ['sandli', '', ''],\n",
       " ['neet', '', ''],\n",
       " ['fatane', '', ''],\n",
       " ['routing', '', ''],\n",
       " ['nauner', '\\n', ''],\n",
       " ['pisa', '', ''],\n",
       " ['clasen', '\\n', ''],\n",
       " ['palaari', '', ''],\n",
       " ['alive', '', '']]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0c56620f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({\"Test Examples - 50\": wandb.Table(data=data_log, columns=[\"Input Text\", \"Predicted Text\", \"True Text\"])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0633fbf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
