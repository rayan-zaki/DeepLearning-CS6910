{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3mLsA2jN0nae",
    "outputId": "91fb7c2a-0a50-4daa-e6c3-cfeda287df0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wandb\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/5d/20ab24504de2669c9a76a50c9bdaeb44a440b0e5e4b92be881ed323857b1/wandb-0.10.26-py2.py3-none-any.whl (2.1MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1MB 5.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1)\n",
      "Collecting pathtools\n",
      "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
      "Collecting GitPython>=1.0.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/99/98019716955ba243657daedd1de8f3a88ca1f5b75057c38e959db22fb87b/GitPython-3.1.14-py3-none-any.whl (159kB)\n",
      "\u001b[K     |████████████████████████████████| 163kB 21.2MB/s \n",
      "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
      "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
      "Collecting configparser>=3.8.1\n",
      "  Downloading https://files.pythonhosted.org/packages/fd/01/ff260a18caaf4457eb028c96eeb405c4a230ca06c8ec9c1379f813caa52e/configparser-5.0.2-py3-none-any.whl\n",
      "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
      "Collecting shortuuid>=0.5.0\n",
      "  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
      "Collecting subprocess32>=3.5.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
      "\u001b[K     |████████████████████████████████| 102kB 7.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.12.4)\n",
      "Collecting sentry-sdk>=0.4.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/92/5a33be64990ba815364a8f2dd9e6f51de60d23dfddafb4f1fc5577d4dc64/sentry_sdk-1.0.0-py2.py3-none-any.whl (131kB)\n",
      "\u001b[K     |████████████████████████████████| 133kB 28.1MB/s \n",
      "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 5.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2020.12.5)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.0->wandb) (54.2.0)\n",
      "Collecting smmap<5,>=3.0.1\n",
      "  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n",
      "Building wheels for collected packages: pathtools, subprocess32\n",
      "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pathtools: filename=pathtools-0.1.2-cp37-none-any.whl size=8786 sha256=a6ba030a1c27ce42d1a41afdf7f2bebf22122bfd4c3ef63f10c6d12b0494a175\n",
      "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
      "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp37-none-any.whl size=6489 sha256=3008bcfac1d706a7f4242b0d9edadabae4fc19c8913610e9a7abddbc01dd990d\n",
      "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
      "Successfully built pathtools subprocess32\n",
      "Installing collected packages: pathtools, smmap, gitdb, GitPython, docker-pycreds, configparser, shortuuid, subprocess32, sentry-sdk, wandb\n",
      "Successfully installed GitPython-3.1.14 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.7 pathtools-0.1.2 sentry-sdk-1.0.0 shortuuid-1.0.1 smmap-4.0.0 subprocess32-3.5.4 wandb-0.10.26\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import shutil\n",
    "import os\n",
    "!pip install wandb\n",
    "import wandb\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "import sys\n",
    "sys.path.append('./drive/MyDrive/Colab Notebooks/CS6910/Part A/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e9W46pZXB_cn",
    "outputId": "b3b02375-a9a8-4c79-e507-f9d4f3389127"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: wandb in /usr/local/lib/python3.7/dist-packages (0.10.26)\n",
      "Requirement already satisfied, skipping upgrade: sentry-sdk>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: subprocess32>=3.5.3 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.5.4)\n",
      "Requirement already satisfied, skipping upgrade: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied, skipping upgrade: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
      "Requirement already satisfied, skipping upgrade: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.14)\n",
      "Requirement already satisfied, skipping upgrade: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
      "Requirement already satisfied, skipping upgrade: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
      "Requirement already satisfied, skipping upgrade: configparser>=3.8.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.0.2)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.12.4)\n",
      "Requirement already satisfied, skipping upgrade: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
      "Requirement already satisfied, skipping upgrade: urllib3>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from sentry-sdk>=0.4.0->wandb) (1.24.3)\n",
      "Requirement already satisfied, skipping upgrade: certifi in /usr/local/lib/python3.7/dist-packages (from sentry-sdk>=0.4.0->wandb) (2020.12.5)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.7)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.0->wandb) (54.2.0)\n",
      "Requirement already satisfied, skipping upgrade: smmap<5,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (4.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YweJmV52B_UV"
   },
   "outputs": [],
   "source": [
    "from torchvision.transforms import RandomCrop, RandomResizedCrop, RandomHorizontalFlip, Resize, CenterCrop, ToTensor, Normalize, Compose\n",
    "\n",
    "## Dataset info\n",
    "iNaturalist = {\n",
    "    'Normalize': {\n",
    "        'mean': (0.485, 0.456, 0.406),\n",
    "        'std':  (0.229, 0.224, 0.225)\n",
    "    }\n",
    "}\n",
    "\n",
    "## Dataloaders\n",
    "def data_loader(train_data, val_data, test_data, batchSize):\n",
    "    train_dataLoader = torch.utils.data.DataLoader(train_data, batch_size=batchSize, shuffle=True)\n",
    "    val_dataLoader = torch.utils.data.DataLoader(val_data, batch_size=batchSize, shuffle=True)\n",
    "    test_dataLoader = torch.utils.data.DataLoader(test_data, batch_size=batchSize, shuffle=False)\n",
    "    loaders = {\n",
    "        'train' : train_dataLoader,\n",
    "        'valid' : val_dataLoader,\n",
    "        'test'  : test_dataLoader\n",
    "    }\n",
    "    return loaders\n",
    "\n",
    "\n",
    "## transforms to match model input dims\n",
    "def transform():\n",
    "    \n",
    "    resize = 224     #128 #32\n",
    "    val_resize = 256 #134 #36\n",
    "    val_center_crop = resize\n",
    "    \n",
    "    train_t = Compose([RandomResizedCrop(resize),\n",
    "                       RandomHorizontalFlip(),\n",
    "                       ToTensor(),\n",
    "                       Normalize(**iNaturalist['Normalize'])])\n",
    "    valid_t = Compose([Resize(val_resize),\n",
    "                       CenterCrop(resize),\n",
    "                       ToTensor(),\n",
    "                       Normalize(**iNaturalist['Normalize'])])\n",
    "    test_t = Compose([Resize((resize,resize)), \n",
    "                      ToTensor(), \n",
    "                      Normalize(**iNaturalist['Normalize'])])\n",
    "    \n",
    "    transforms = {\n",
    "        'training':   train_t,\n",
    "        'validation': valid_t,\n",
    "        'test': test_t\n",
    "    }\n",
    "    \n",
    "    return transforms\n",
    "\n",
    "## Load dataset fn\n",
    "def load_datasets():\n",
    "    transforms=transform()\n",
    "    trainset  = torchvision.datasets.ImageFolder('./drive/MyDrive/Colab Notebooks/CS6910/Part A/inaturalist_12K/train_val/train', transforms['training'])\n",
    "    valset    = torchvision.datasets.ImageFolder('./drive/MyDrive/Colab Notebooks/CS6910/Part A/inaturalist_12K/train_val/val', transforms['validation'])\n",
    "    testset   = torchvision.datasets.ImageFolder('./drive/MyDrive/Colab Notebooks/CS6910/Part A/inaturalist_12K/val', transforms['test'])\n",
    "    \n",
    "    return trainset, valset, testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "65C6xZDCB_Fh",
    "outputId": "9f49e345-473f-4249-97e4-cb7a23f24516"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    }
   ],
   "source": [
    "!wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f42tJXCTCKPU"
   },
   "outputs": [],
   "source": [
    "# check if CUDA is available\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda == True:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0SlIMBoeCKL8"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "datasetTrain, datasetVal, datasetTest = load_datasets()\n",
    "loaders = data_loader(datasetTrain, datasetVal, datasetTest, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jo6VEAq2CKJy"
   },
   "outputs": [],
   "source": [
    "modelName = 'CNN_5Layers_iNaturalist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PSj7Qdz3CKHf"
   },
   "outputs": [],
   "source": [
    "def act_fn(act_name):\n",
    "    if act_name==\"relu\":\n",
    "        return nn.ReLU(inplace=True)\n",
    "    \n",
    "    elif act_name==\"sigmoid\":\n",
    "        return nn.Sigmoid(inplace=True)\n",
    "    \n",
    "    elif act_name==\"tanh\":\n",
    "        return nn.Tanh(inplace==True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vs0XhDyRCKFJ"
   },
   "outputs": [],
   "source": [
    "class conv_block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size = 3 ,BN=True , NL=\"relu\", stride = 1, padding = 0):\n",
    "        super(conv_block, self).__init__()\n",
    "        self.BN=BN\n",
    "        self.NL=NL\n",
    "        k = kernel_size\n",
    "        \n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size = k, stride = stride, padding = padding, bias=False)\n",
    "        \n",
    "        if self.BN==True:\n",
    "            self.bn = nn.BatchNorm2d(out_channels, eps=0.001)\n",
    "            \n",
    "        self.act = act_fn(NL)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        \n",
    "        if self.BN==True:\n",
    "            x = self.bn(x)\n",
    "        \n",
    "        return self.act(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XSiMcKeGCKCx"
   },
   "outputs": [],
   "source": [
    "class fc_block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, BN=False , NL=\"relu\"):\n",
    "        super(fc_block, self).__init__()\n",
    "        self.BN=BN\n",
    "        self.NL=NL\n",
    "        self.fc = nn.Linear(in_channels, out_channels)\n",
    "        \n",
    "        if self.BN==True:\n",
    "            self.bn = nn.BatchNorm2d(out_channels, eps=0.001)\n",
    "            \n",
    "        self.act = act_fn(NL)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        if self.BN==True:\n",
    "            x = self.bn(x)\n",
    "        \n",
    "        x = self.act(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AUsCkOTTCKAM"
   },
   "outputs": [],
   "source": [
    "def get_fc_in(input_dim, kernel_size_list, no_kernel_list):\n",
    "    H = input_dim\n",
    "    fc_in = H - kernel_size_list[0] + 1 # conv1\n",
    "    fc_in = (fc_in - 2) //2  + 1 # max pool 1\n",
    "    fc_in = fc_in - kernel_size_list[1] + 1 # conv2\n",
    "    fc_in = (fc_in - 2) //2  + 1 # max pool 2\n",
    "    fc_in = fc_in - kernel_size_list[2] + 1 #conv3\n",
    "    fc_in = (fc_in - 2) //2  + 1 # max pool 3\n",
    "    fc_in = fc_in - kernel_size_list[3] + 1 #conv4\n",
    "    fc_in = (fc_in - 2) //2  + 1 # max pool 4\n",
    "    fc_in = fc_in - kernel_size_list[4] + 1 #conv5\n",
    "    fc_in = (fc_in - 2) //2  + 1 # max pool 5\n",
    "    #print(fc_in)\n",
    "    return fc_in * fc_in * no_kernel_list[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CeTg6MFvCJ9m"
   },
   "outputs": [],
   "source": [
    "class CNN_5layer(nn.Module):\n",
    "    def __init__(self, kernel_size_list, no_kernel_list, act_fn_dict, dropout_list, fc1_nodes, no_classes):\n",
    "        super(CNN_5layer, self).__init__()\n",
    "        self.dropout_list = dropout_list\n",
    "        self.input_dim = 224\n",
    "        #self.input_dim = 128\n",
    "        self.conv1 = conv_block(3, no_kernel_list[0], kernel_size=kernel_size_list[0], BN=False, NL=act_fn_dict['conv1'])\n",
    "        self.maxpool1 = nn.MaxPool2d((2, 2))\n",
    "        self.conv2 = conv_block(no_kernel_list[0], no_kernel_list[1], kernel_size=kernel_size_list[1], BN=True, NL=act_fn_dict['conv2'])\n",
    "        self.maxpool2 = nn.MaxPool2d((2, 2))\n",
    "        \n",
    "        if self.dropout_list[0]!=0:\n",
    "            self.dropout1 = nn.Dropout(dropout_list[0])\n",
    "\n",
    "        self.conv3 = conv_block(no_kernel_list[1], no_kernel_list[2], kernel_size=kernel_size_list[2], BN=True, NL=act_fn_dict['conv3'])\n",
    "        self.maxpool3 = nn.MaxPool2d((2, 2))\n",
    "        self.conv4 = conv_block(no_kernel_list[2], no_kernel_list[3], kernel_size=kernel_size_list[3], BN=True, NL=act_fn_dict['conv4'])\n",
    "        self.maxpool4 = nn.MaxPool2d((2, 2))\n",
    "        \n",
    "        if self.dropout_list[1]!=0:\n",
    "            self.dropout2 = nn.Dropout(dropout_list[1])\n",
    "\n",
    "        self.conv5 = conv_block(no_kernel_list[3], no_kernel_list[4], kernel_size=kernel_size_list[4], BN=True, NL=act_fn_dict['conv5'])\n",
    "        self.maxpool5 = nn.MaxPool2d((2, 2))\n",
    "        \n",
    "        self.fc1_in_features = get_fc_in(self.input_dim, kernel_size_list, no_kernel_list)\n",
    "        \n",
    "        self.fc1 = fc_block(self.fc1_in_features, fc1_nodes , NL=act_fn_dict['fc1'])\n",
    "        \n",
    "        if self.dropout_list[2]!=0:\n",
    "            self.dropout3 = nn.Dropout(dropout_list[2])\n",
    "        \n",
    "        self.fc2 = nn.Linear(fc1_nodes, no_classes)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        if x.shape[2]!=self.input_dim:\n",
    "            print(\"input dim not matched\")\n",
    "            return\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        \n",
    "        if self.dropout_list[0]!=0:\n",
    "            x = self.dropout1(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.maxpool3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.maxpool4(x)\n",
    "        \n",
    "        if self.dropout_list[1]!=0:\n",
    "            x = self.dropout2(x)\n",
    "        \n",
    "        x = self.conv5(x)\n",
    "        x = self.maxpool5(x)\n",
    "        \n",
    "        x = x.view(x.shape[0], -1)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        if self.dropout_list[2]!=0:\n",
    "            x = self.dropout3(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vLnJXHaSCJ6e"
   },
   "outputs": [],
   "source": [
    "def train(start_epochs, n_epochs, valid_loss_min_input, loaders, model, optimizer, criterion,scheduler, use_cuda):\n",
    "    valid_loss_min = valid_loss_min_input \n",
    "    \n",
    "    for epoch in range(start_epochs, start_epochs+n_epochs):\n",
    "        \n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        \n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        tnum_correct = 0\n",
    "        tnum_examples = 0\n",
    "        for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "                \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            correct = torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1],target).view(-1)\n",
    "            tnum_correct += torch.sum(correct).item()\n",
    "            tnum_examples += correct.shape[0]\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
    "        train_acc = tnum_correct / tnum_examples\n",
    "        \n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        model.eval()\n",
    "        num_correct = 0\n",
    "        num_examples = 0\n",
    "        for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
    "            \n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            \n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n",
    "            \n",
    "            correct = torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1],target).view(-1)\n",
    "            num_correct += torch.sum(correct).item()\n",
    "            num_examples += correct.shape[0]\n",
    "            \n",
    "        train_loss = train_loss/len(loaders['train'].dataset)\n",
    "        valid_loss = valid_loss/len(loaders['valid'].dataset)\n",
    "        valid_acc = num_correct / num_examples\n",
    "        scheduler.step()\n",
    "        \n",
    "        print('Epoch: {}\\tTraining Loss: {:.6f}\\tTrain Accuracy: {:.2f}\\tValidation Loss: {:.6f}\\tvalidation Accuracy: {:.2f}'.format(\n",
    "            epoch, \n",
    "            train_loss,\n",
    "            train_acc,\n",
    "            valid_loss,\n",
    "            valid_acc\n",
    "            ))\n",
    "        \n",
    "        wandb.log({'epoch': epoch,'train loss': train_loss,'train accuracy': train_acc,\n",
    "                   'val loss': valid_loss, 'val accuracy': valid_acc})\n",
    "        \n",
    "        if valid_loss <= valid_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f})'.format(valid_loss_min,valid_loss))\n",
    "            valid_loss_min = valid_loss\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YWNybsG4CJ3y"
   },
   "outputs": [],
   "source": [
    "def config_str_list_int(s):\n",
    "    l=list(map(int, s[3:].split('-')))\n",
    "    return l\n",
    "\n",
    "def config_str_list_float(s):\n",
    "    l=list(map(float, s.split('-')))\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7TSa0B-FC47I"
   },
   "outputs": [],
   "source": [
    "def sp_train():\n",
    "    config_defaults = {\n",
    "        'epochs': 25,\n",
    "        'kernel_size_config':'1) 5-5-3-3-3' ,\n",
    "        'no_kernel_config':'1) 32-32-32-32-32',\n",
    "        'dropout_config':'0-0-0.4',\n",
    "        'fc1_nodes': 512,\n",
    "        'batch_size': 64\n",
    "    }\n",
    "    # Initialize a new wandb run\n",
    "    wandb.init(config=config_defaults)\n",
    "    # Config is a variable that holds and saves hyperparameters and inputs\n",
    "    config = wandb.config\n",
    "    run_name=\"kSizes:[\"+config.kernel_size_config+\"] kNumbers:[\"+config.no_kernel_config+\"] dp:[\"+config.dropout_config+\"] fc1:[\"+str(config.fc1_nodes)+\"] bs:[\"+str(config.batch_size)+\"]\"\n",
    "    wandb.run.name=run_name\n",
    "    \n",
    "    act_fn_dict = {\n",
    "        'conv1':'relu',\n",
    "        'conv2':'relu',\n",
    "        'conv3':'relu',\n",
    "        'conv4':'relu',\n",
    "        'conv5':'relu',\n",
    "        'fc1':'relu'\n",
    "    }\n",
    "    \n",
    "    kernel_size_list = config_str_list_int(config.kernel_size_config)\n",
    "    no_kernel_list = config_str_list_int(config.no_kernel_config)\n",
    "    dropout_list = config_str_list_float(config.dropout_config)\n",
    "    fc1_nodes = config.fc1_nodes\n",
    "    no_classes = 10\n",
    "    \n",
    "    model = CNN_5layer(kernel_size_list, no_kernel_list, act_fn_dict, dropout_list, fc1_nodes, no_classes)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "    scheduler = StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    trained_model = train(start_epochs = 1,\n",
    "                      n_epochs = config.epochs,\n",
    "                      valid_loss_min_input = np.Inf,\n",
    "                      loaders = loaders,\n",
    "                      model = model,\n",
    "                      optimizer = optimizer,\n",
    "                      criterion = criterion,\n",
    "                      scheduler = scheduler,\n",
    "                      use_cuda = use_cuda\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v2yAGc2DC43o"
   },
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'grid', \n",
    "    'metric': {\n",
    "      'name': 'val accuracy',\n",
    "      'goal': 'maximize'   \n",
    "    },\n",
    "    'parameters': {\n",
    "        'epochs': {\n",
    "            'values':[25]\n",
    "        },\n",
    "        'kernel_size_config':{\n",
    "            'values': ['1) 5-5-3-3-3', \n",
    "                       '2) 3-3-3-3-3', \n",
    "                       '3) 3-3-3-5-5'\n",
    "                       ]\n",
    "        },\n",
    "        'no_kernel_config': {\n",
    "            'values':['1) 32-32-32-32-32', \n",
    "                      '2) 64-64-32-32-16', \n",
    "                      '3) 32-32-64-64-128'] \n",
    "        },\n",
    "        'dropout_config':{\n",
    "            'values':['0-0-0.5']\n",
    "        },\n",
    "        'fc1_nodes':{\n",
    "            'values': [512,1024]\n",
    "        },\n",
    "        'batch_size': {\n",
    "            'values':[64]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rHukPk1Brv4o"
   },
   "outputs": [],
   "source": [
    "#sweep_id = wandb.sweep(sweep_config, project=modelName+\"_Sweep_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qN1yMt9Irvhd"
   },
   "outputs": [],
   "source": [
    "#wandb.agent(sweep_id, sp_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 322
    },
    "id": "XMmusz7bC41k",
    "outputId": "29e9e7fe-4445-49dd-b46b-4b04131102aa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ohyvu2tr with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_config: 0-0-0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfc1_nodes: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size_config: 3) 3-3-3-5-5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tno_kernel_config: 3) 32-32-64-64-128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrayanz\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.26<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">playful-sweep-18</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/rayanz/CNN_5Layers_iNaturalist_Sweep_1\" target=\"_blank\">https://wandb.ai/rayanz/CNN_5Layers_iNaturalist_Sweep_1</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/rayanz/CNN_5Layers_iNaturalist_Sweep_1/sweeps/m9juzani\" target=\"_blank\">https://wandb.ai/rayanz/CNN_5Layers_iNaturalist_Sweep_1/sweeps/m9juzani</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/rayanz/CNN_5Layers_iNaturalist_Sweep_1/runs/ohyvu2tr\" target=\"_blank\">https://wandb.ai/rayanz/CNN_5Layers_iNaturalist_Sweep_1/runs/ohyvu2tr</a><br/>\n",
       "                Run data is saved locally in <code>/content/wandb/run-20210415_180414-ohyvu2tr</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\tTraining Loss: 0.000244\tTrain Accuracy: 0.19\tValidation Loss: 0.002030\tvalidation Accuracy: 0.26\n",
      "Validation loss decreased (inf --> 0.002030)\n"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id = 'm9juzani', project=modelName+\"_Sweep_1\", function = sp_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HynVv8CLC4y8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5vS5A0EPC4wV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l9tWlnfzC4rw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mEHHTDB-C4pI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TX-PbVqAB-wt"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Sweep PartA.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
