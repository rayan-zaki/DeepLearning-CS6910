{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All 4 Pretrained Models sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_val  val\n"
     ]
    }
   ],
   "source": [
    "!ls '/kaggle/input/inaturalist/inaturalist_12K'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xception.py\n"
     ]
    }
   ],
   "source": [
    "!ls '/kaggle/input/xception/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inceptionresnetv2.py\n"
     ]
    }
   ],
   "source": [
    "!ls '/kaggle/input/incepresv2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import RandomResizedCrop, RandomHorizontalFlip, Resize, CenterCrop, ToTensor, Normalize, Compose\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import shutil\n",
    "import sys\n",
    "sys.path.append('/kaggle/input/xception/')\n",
    "sys.path.append('/kaggle/input/incepresv2/')\n",
    "from xception import*\n",
    "from inceptionresnetv2 import*\n",
    "## Dataset info\n",
    "iNaturalist = {\n",
    "    'Normalize': {\n",
    "        'mean': (0.485, 0.456, 0.406),\n",
    "        'std':  (0.229, 0.224, 0.225)\n",
    "    }\n",
    "}\n",
    "\n",
    "## Dataloaders\n",
    "def data_loader(train_data, val_data, test_data, batchSize):\n",
    "    train_dataLoader = torch.utils.data.DataLoader(train_data, batch_size=batchSize, shuffle=True)\n",
    "    val_dataLoader = torch.utils.data.DataLoader(val_data, batch_size=batchSize, shuffle=True)\n",
    "    test_dataLoader = torch.utils.data.DataLoader(test_data, batch_size=batchSize, shuffle=False)\n",
    "    loaders = {\n",
    "        'train' : train_dataLoader,\n",
    "        'valid' : val_dataLoader,\n",
    "        'test'  : test_dataLoader\n",
    "    }\n",
    "    return loaders\n",
    "\n",
    "## getModdel fn\n",
    "def getModel(modelName):\n",
    "    import torchvision as tv \n",
    "    model = None\n",
    "    \n",
    "    if modelName == 'InceptionV3':\n",
    "        model = tv.models.inception_v3(pretrained=True)\n",
    "    elif modelName == 'InceptionResNetV2':\n",
    "        model = inceptionresnetv2(pretrained='imagenet')\n",
    "    elif modelName == 'ResNet50':\n",
    "        model = tv.models.resnet50(pretrained=True)\n",
    "    elif modelName == 'Xception':\n",
    "        model = xception(pretrained=True)\n",
    "    elif modelName == 'Vgg16':\n",
    "        model = tv.models.vgg16(pretrained=True)\n",
    "        \n",
    "    return model\n",
    "\n",
    "## transforms to match model input dims\n",
    "def transform(modelName):\n",
    "    if modelName == 'Xception' or modelName == 'InceptionV3' or modelName == 'InceptionResNetV2':\n",
    "        resize = 299\n",
    "        val_resize = 333\n",
    "        val_center_crop = resize\n",
    "        \n",
    "    \n",
    "    else:\n",
    "        resize = 224\n",
    "        val_resize = 256\n",
    "        val_center_crop = resize\n",
    "    \n",
    "    \n",
    "    train_t = Compose([RandomResizedCrop(resize),\n",
    "                       RandomHorizontalFlip(),\n",
    "                       ToTensor(),\n",
    "                       Normalize(**iNaturalist['Normalize'])])\n",
    "    valid_t = Compose([Resize(val_resize),\n",
    "                       CenterCrop(resize),\n",
    "                       ToTensor(),\n",
    "                       Normalize(**iNaturalist['Normalize'])])\n",
    "    test_t = Compose([Resize((resize,resize)), \n",
    "                      ToTensor(), \n",
    "                      Normalize(**iNaturalist['Normalize'])])\n",
    "    \n",
    "    transforms = {\n",
    "        'training':   train_t,\n",
    "        'validation': valid_t,\n",
    "        'test': test_t\n",
    "    }\n",
    "    \n",
    "    return transforms\n",
    "\n",
    "## Load dataset fn\n",
    "def load_datasets(modelName):\n",
    "    transforms=transform(modelName)\n",
    "    trainset  = torchvision.datasets.ImageFolder('/kaggle/input/inaturalist/inaturalist_12K/train_val/train', transforms['training'])\n",
    "    valset    = torchvision.datasets.ImageFolder('/kaggle/input/inaturalist/inaturalist_12K/train_val/val', transforms['validation'])\n",
    "    testset   = torchvision.datasets.ImageFolder('/kaggle/input/inaturalist/inaturalist_12K/val', transforms['test'])\n",
    "    \n",
    "    return trainset, valset, testset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.7/site-packages (0.10.23)\n",
      "Requirement already satisfied: subprocess32>=3.5.3 in /opt/conda/lib/python3.7/site-packages (from wandb) (3.5.4)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (2.25.1)\n",
      "Requirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.15.0)\n",
      "Requirement already satisfied: Click>=7.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (7.1.2)\n",
      "Requirement already satisfied: configparser>=3.8.1 in /opt/conda/lib/python3.7/site-packages (from wandb) (5.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from wandb) (2.8.1)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.7/site-packages (from wandb) (5.3.1)\n",
      "Requirement already satisfied: sentry-sdk>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.0.0)\n",
      "Requirement already satisfied: pathtools in /opt/conda/lib/python3.7/site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.0.1)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (3.1.13)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (3.15.6)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (5.8.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.7/site-packages (from GitPython>=1.0.0->wandb) (4.0.5)\n",
      "Requirement already satisfied: smmap<4,>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (3.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.26.3)\n",
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.7/site-packages (0.10.23)\n",
      "Collecting wandb\n",
      "  Downloading wandb-0.10.25-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 2.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: shortuuid>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (2.25.1)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (3.1.13)\n",
      "Requirement already satisfied: subprocess32>=3.5.3 in /opt/conda/lib/python3.7/site-packages (from wandb) (3.5.4)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from wandb) (2.8.1)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.15.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (3.15.6)\n",
      "Requirement already satisfied: pathtools in /opt/conda/lib/python3.7/site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (5.8.0)\n",
      "Requirement already satisfied: configparser>=3.8.1 in /opt/conda/lib/python3.7/site-packages (from wandb) (5.0.2)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.7/site-packages (from wandb) (5.3.1)\n",
      "Requirement already satisfied: Click>=7.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (7.1.2)\n",
      "Requirement already satisfied: sentry-sdk>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.0.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.7/site-packages (from GitPython>=1.0.0->wandb) (4.0.5)\n",
      "Requirement already satisfied: smmap<4,>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (3.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.26.3)\n",
      "Installing collected packages: wandb\n",
      "  Attempting uninstall: wandb\n",
      "    Found existing installation: wandb 0.10.23\n",
      "    Uninstalling wandb-0.10.23:\n",
      "      Successfully uninstalled wandb-0.10.23\n",
      "Successfully installed wandb-0.10.25\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "!pip install wandb\n",
    "!pip install wandb --upgrade\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:  ········································\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if CUDA is available\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda == True:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_change_classifier(model):\n",
    "    modelName = model.name\n",
    "    if modelName == 'InceptionV3':\n",
    "        model.fc = nn.Sequential(nn.Linear(model.fc.in_features,500),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(),\n",
    "                                 nn.Linear(500,10))\n",
    "\n",
    "\n",
    "    if modelName == 'Vgg16':\n",
    "        model.classifier[6] = nn.Sequential(nn.Linear(model.classifier[6].in_features,500),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(),\n",
    "                                 nn.Linear(500,10))\n",
    "\n",
    "\n",
    "    if modelName == 'ResNet50':\n",
    "        model.fc = nn.Sequential(nn.Linear(model.fc.in_features,500),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(),\n",
    "                             nn.Linear(500,10))\n",
    "\n",
    "    if modelName == 'Xception':\n",
    "        model.fc = nn.Sequential(nn.Linear(model.fc.in_features,500),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(),\n",
    "                             nn.Linear(500,10))\n",
    "        \n",
    "    if modelName == 'InceptionResNetV2':\n",
    "        model.last_linear = nn.Sequential(nn.Linear(model.last_linear.in_features,500),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(),\n",
    "                             nn.Linear(500,10))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(start_epochs, n_epochs, loaders, model, optimizer, criterion, use_cuda):\n",
    "    \n",
    "    \n",
    "    for epoch in range(start_epochs, start_epochs+n_epochs):\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        \n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        tnum_correct = 0\n",
    "        tnum_examples = 0\n",
    "        for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "                \n",
    "            optimizer.zero_grad()\n",
    "            if model.name == 'InceptionV3':\n",
    "                output, aux_output = model(data)\n",
    "                loss1 = criterion(output, target)\n",
    "                loss2 = criterion(aux_output, target)\n",
    "                loss = loss1 + 0.4*loss2\n",
    "                \n",
    "            else:\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "            \n",
    "            correct = torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1],target).view(-1)\n",
    "            tnum_correct += torch.sum(correct).item()\n",
    "            tnum_examples += correct.shape[0]\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
    "        train_acc = tnum_correct / tnum_examples\n",
    "        \n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        model.eval()\n",
    "        num_correct = 0\n",
    "        num_examples = 0\n",
    "        for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
    "            \n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            \n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n",
    "            \n",
    "            correct = torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1],target).view(-1)\n",
    "            num_correct += torch.sum(correct).item()\n",
    "            num_examples += correct.shape[0]\n",
    "            \n",
    "        train_loss = train_loss/len(loaders['train'].dataset)\n",
    "        valid_loss = valid_loss/len(loaders['valid'].dataset)\n",
    "        valid_acc = num_correct / num_examples\n",
    "        \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tTrain Accuracy: {:.2f} \\tValidation Loss: {:.6f} \\tvalidation Accuracy: {:.2f}'.format(\n",
    "            epoch, \n",
    "            train_loss,\n",
    "            train_acc,\n",
    "            valid_loss,\n",
    "            valid_acc\n",
    "            ))\n",
    "        \n",
    "        wandb.log({'epoch': epoch,'train loss': train_loss,'train accuracy': train_acc,\n",
    "                   'val loss': valid_loss, 'val accuracy': valid_acc})\n",
    "            \n",
    "    # return trained model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sp_train():\n",
    "    config_defaults = {\n",
    "        'model_name':'ResNet50',\n",
    "        'preTrain_epochs': 3,\n",
    "        'fineTune_epochs': 5,\n",
    "        'learning_rate_1': 1e-4,\n",
    "        'learning_rate_2': 1e-4,\n",
    "        'batchnorm_pretrain':'YES',\n",
    "        'optimizer': 'sgd'\n",
    "    }\n",
    "    # Initialize a new wandb run\n",
    "    wandb.init(config=config_defaults)\n",
    "    # Config is a variable that holds and saves hyperparameters and inputs\n",
    "    config = wandb.config\n",
    "    run_name=\"Model:[\"+config.model_name+\"] pT_ep:[\"+str(config.preTrain_epochs)+\"] fT_ep:[\"+str(config.fineTune_epochs)+\"] lr1:[\"+str(config.learning_rate_1)+\"] lr2:[\"+str(config.learning_rate_2)+\"] op:[\"+config.optimizer+\"] BNpT:[\"+config.batchnorm_pretrain+\"]\"\n",
    "    wandb.run.name=run_name\n",
    "    modelName = config.model_name\n",
    "    model = getModel(modelName)\n",
    "    model.name = modelName\n",
    "    if modelName =='Xception' or modelName == 'InceptionResNetV2':\n",
    "        batch_size = 4\n",
    "    else: \n",
    "        batch_size = 8\n",
    "    \n",
    "    datasetTrain, datasetVal, datasetTest = load_datasets(modelName)\n",
    "    \n",
    "    loaders = data_loader(datasetTrain, datasetVal, datasetTest, batch_size)\n",
    "    \n",
    "    # Get Batchnorm Layers\n",
    "    msBN = list(filter(lambda m: type(m) == torch.nn.modules.BatchNorm2d, model.modules()))\n",
    "    \n",
    "    # Freezing layer\n",
    "    for param in model.parameters():\n",
    "        if param.requires_grad:\n",
    "            param.requires_grad=False\n",
    "    \n",
    "    model_change_classifier(model)\n",
    "    \n",
    "    # Batchnorm layers unfreeze\n",
    "    if config.batchnorm_pretrain=='YES':\n",
    "        for i, m in enumerate(msBN):\n",
    "            for param in m.parameters():\n",
    "                param.requires_grad= True\n",
    "                \n",
    "    model = model.to(device)\n",
    "    \n",
    "    if config.optimizer=='sgd':\n",
    "        optimizer = optim.SGD(model.parameters(), lr=config.learning_rate_1, momentum = 0.9)\n",
    "    elif config.optimizer=='adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=config.learning_rate_1, betas=(0.9, 0.999))\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    trained_model = train(start_epochs = 1,\n",
    "                      n_epochs = config.preTrain_epochs,\n",
    "                      loaders = loaders,\n",
    "                      model = model,\n",
    "                      optimizer = optimizer,\n",
    "                      criterion = criterion,\n",
    "                      use_cuda = use_cuda\n",
    "                     )\n",
    "    \n",
    "    #model, optimizer, start_epoch, valid_loss, valid_acc, valid_loss_min = load_ckp(ckp_path, model, optimizer)\n",
    "    \n",
    "    for name, param in trained_model.named_parameters():\n",
    "        param.requires_grad = True\n",
    "        \n",
    "    for g in optimizer.param_groups:\n",
    "        g['lr'] = config.learning_rate_2\n",
    "        \n",
    "    trained_model = train(start_epochs = config.preTrain_epochs+1,\n",
    "                      n_epochs = config.fineTune_epochs,\n",
    "                      loaders = loaders,\n",
    "                      model = trained_model,\n",
    "                      optimizer = optimizer,\n",
    "                      criterion = criterion,\n",
    "                      use_cuda = use_cuda\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'grid', \n",
    "    'metric': {\n",
    "      'name': 'val accuracy',\n",
    "      'goal': 'maximize'   \n",
    "    },\n",
    "    'parameters': {\n",
    "        'model_name': {\n",
    "            #'values':[modelName]\n",
    "            'values':['InceptionV3', 'ResNet50','Xception','InceptionResNetV2']\n",
    "        },\n",
    "        'preTrain_epochs': {\n",
    "            'values':[3]\n",
    "        },\n",
    "        'fineTune_epochs': {\n",
    "            'values': [5]\n",
    "        },\n",
    "        'learning_rate_1': {\n",
    "            'values':[0.001] \n",
    "        },\n",
    "        'learning_rate_2':{\n",
    "            'values':[0.0001]\n",
    "        },\n",
    "        'batchnorm_pretrain':{\n",
    "            'values': ['YES']\n",
    "        },\n",
    "        'optimizer': {\n",
    "            'values':['sgd']\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: f6ktmkwp\n",
      "Sweep URL: https://wandb.ai/rayanz/All_Models_Sweep_1/sweeps/f6ktmkwp\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"All_Models_Sweep_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: tpyzlg5g with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchnorm_pretrain: YES\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfineTune_epochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate_1: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate_2: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_name: InceptionV3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpreTrain_epochs: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.25<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">playful-sweep-1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/rayanz/All_Models_Sweep_1\" target=\"_blank\">https://wandb.ai/rayanz/All_Models_Sweep_1</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/rayanz/All_Models_Sweep_1/sweeps/f6ktmkwp\" target=\"_blank\">https://wandb.ai/rayanz/All_Models_Sweep_1/sweeps/f6ktmkwp</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/rayanz/All_Models_Sweep_1/runs/tpyzlg5g\" target=\"_blank\">https://wandb.ai/rayanz/All_Models_Sweep_1/runs/tpyzlg5g</a><br/>\n",
       "                Run data is saved locally in <code>/kaggle/working/wandb/run-20210411_110435-tpyzlg5g</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.000595 \tTrain Accuracy: 0.40 \tValidation Loss: 0.000473 \tvalidation Accuracy: 0.77\n",
      "Epoch: 2 \tTraining Loss: 0.000457 \tTrain Accuracy: 0.60 \tValidation Loss: 0.000346 \tvalidation Accuracy: 0.80\n",
      "Epoch: 3 \tTraining Loss: 0.000383 \tTrain Accuracy: 0.65 \tValidation Loss: 0.000336 \tvalidation Accuracy: 0.80\n",
      "Epoch: 4 \tTraining Loss: 0.000235 \tTrain Accuracy: 0.67 \tValidation Loss: 0.000270 \tvalidation Accuracy: 0.83\n",
      "Epoch: 5 \tTraining Loss: 0.000179 \tTrain Accuracy: 0.71 \tValidation Loss: 0.000250 \tvalidation Accuracy: 0.86\n",
      "Epoch: 6 \tTraining Loss: 0.000162 \tTrain Accuracy: 0.73 \tValidation Loss: 0.000235 \tvalidation Accuracy: 0.85\n",
      "Epoch: 7 \tTraining Loss: 0.000150 \tTrain Accuracy: 0.75 \tValidation Loss: 0.000230 \tvalidation Accuracy: 0.86\n",
      "Epoch: 8 \tTraining Loss: 0.000138 \tTrain Accuracy: 0.76 \tValidation Loss: 0.000226 \tvalidation Accuracy: 0.86\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 2130<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/kaggle/working/wandb/run-20210411_110435-tpyzlg5g/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/kaggle/working/wandb/run-20210411_110435-tpyzlg5g/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>8</td></tr><tr><td>train loss</td><td>0.00014</td></tr><tr><td>train accuracy</td><td>0.7641</td></tr><tr><td>val loss</td><td>0.00023</td></tr><tr><td>val accuracy</td><td>0.8645</td></tr><tr><td>_runtime</td><td>2474</td></tr><tr><td>_timestamp</td><td>1618141549</td></tr><tr><td>_step</td><td>7</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>train loss</td><td>█▆▅▂▂▁▁▁</td></tr><tr><td>train accuracy</td><td>▁▅▆▆▇▇██</td></tr><tr><td>val loss</td><td>█▄▄▂▂▁▁▁</td></tr><tr><td>val accuracy</td><td>▁▄▃▅▇▇██</td></tr><tr><td>_runtime</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>_timestamp</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>_step</td><td>▁▂▃▄▅▆▇█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">playful-sweep-1</strong>: <a href=\"https://wandb.ai/rayanz/All_Models_Sweep_1/runs/tpyzlg5g\" target=\"_blank\">https://wandb.ai/rayanz/All_Models_Sweep_1/runs/tpyzlg5g</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: jozsbvng with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchnorm_pretrain: YES\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfineTune_epochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate_1: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate_2: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_name: ResNet50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpreTrain_epochs: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.25<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">unique-sweep-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/rayanz/All_Models_Sweep_1\" target=\"_blank\">https://wandb.ai/rayanz/All_Models_Sweep_1</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/rayanz/All_Models_Sweep_1/sweeps/f6ktmkwp\" target=\"_blank\">https://wandb.ai/rayanz/All_Models_Sweep_1/sweeps/f6ktmkwp</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/rayanz/All_Models_Sweep_1/runs/jozsbvng\" target=\"_blank\">https://wandb.ai/rayanz/All_Models_Sweep_1/runs/jozsbvng</a><br/>\n",
       "                Run data is saved locally in <code>/kaggle/working/wandb/run-20210411_114552-jozsbvng</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.000177 \tTrain Accuracy: 0.52 \tValidation Loss: 0.000317 \tvalidation Accuracy: 0.79\n",
      "Epoch: 2 \tTraining Loss: 0.000128 \tTrain Accuracy: 0.66 \tValidation Loss: 0.000285 \tvalidation Accuracy: 0.81\n",
      "Epoch: 3 \tTraining Loss: 0.000122 \tTrain Accuracy: 0.68 \tValidation Loss: 0.000267 \tvalidation Accuracy: 0.83\n",
      "Epoch: 4 \tTraining Loss: 0.000110 \tTrain Accuracy: 0.70 \tValidation Loss: 0.000261 \tvalidation Accuracy: 0.83\n",
      "Epoch: 5 \tTraining Loss: 0.000105 \tTrain Accuracy: 0.72 \tValidation Loss: 0.000249 \tvalidation Accuracy: 0.84\n",
      "Epoch: 6 \tTraining Loss: 0.000098 \tTrain Accuracy: 0.74 \tValidation Loss: 0.000243 \tvalidation Accuracy: 0.84\n",
      "Epoch: 7 \tTraining Loss: 0.000097 \tTrain Accuracy: 0.74 \tValidation Loss: 0.000244 \tvalidation Accuracy: 0.84\n",
      "Epoch: 8 \tTraining Loss: 0.000092 \tTrain Accuracy: 0.77 \tValidation Loss: 0.000238 \tvalidation Accuracy: 0.85\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 3698<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/kaggle/working/wandb/run-20210411_114552-jozsbvng/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/kaggle/working/wandb/run-20210411_114552-jozsbvng/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>8</td></tr><tr><td>train loss</td><td>9e-05</td></tr><tr><td>train accuracy</td><td>0.76535</td></tr><tr><td>val loss</td><td>0.00024</td></tr><tr><td>val accuracy</td><td>0.85</td></tr><tr><td>_runtime</td><td>1932</td></tr><tr><td>_timestamp</td><td>1618143484</td></tr><tr><td>_step</td><td>7</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>train loss</td><td>█▄▃▂▂▁▁▁</td></tr><tr><td>train accuracy</td><td>▁▅▅▆▇▇▇█</td></tr><tr><td>val loss</td><td>█▅▄▃▂▁▁▁</td></tr><tr><td>val accuracy</td><td>▁▃▅▆▆▇▇█</td></tr><tr><td>_runtime</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>_timestamp</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>_step</td><td>▁▂▃▄▅▆▇█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">unique-sweep-2</strong>: <a href=\"https://wandb.ai/rayanz/All_Models_Sweep_1/runs/jozsbvng\" target=\"_blank\">https://wandb.ai/rayanz/All_Models_Sweep_1/runs/jozsbvng</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: nlwcylj8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchnorm_pretrain: YES\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfineTune_epochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate_1: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate_2: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_name: Xception\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpreTrain_epochs: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.25<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">deft-sweep-3</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/rayanz/All_Models_Sweep_1\" target=\"_blank\">https://wandb.ai/rayanz/All_Models_Sweep_1</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/rayanz/All_Models_Sweep_1/sweeps/f6ktmkwp\" target=\"_blank\">https://wandb.ai/rayanz/All_Models_Sweep_1/sweeps/f6ktmkwp</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/rayanz/All_Models_Sweep_1/runs/nlwcylj8\" target=\"_blank\">https://wandb.ai/rayanz/All_Models_Sweep_1/runs/nlwcylj8</a><br/>\n",
       "                Run data is saved locally in <code>/kaggle/working/wandb/run-20210411_121808-nlwcylj8</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.000195 \tTrain Accuracy: 0.52 \tValidation Loss: 0.000351 \tvalidation Accuracy: 0.80\n",
      "Epoch: 2 \tTraining Loss: 0.000129 \tTrain Accuracy: 0.68 \tValidation Loss: 0.000288 \tvalidation Accuracy: 0.82\n",
      "Epoch: 3 \tTraining Loss: 0.000114 \tTrain Accuracy: 0.71 \tValidation Loss: 0.000256 \tvalidation Accuracy: 0.84\n",
      "Epoch: 4 \tTraining Loss: 0.000103 \tTrain Accuracy: 0.74 \tValidation Loss: 0.000241 \tvalidation Accuracy: 0.85\n",
      "Epoch: 5 \tTraining Loss: 0.000099 \tTrain Accuracy: 0.75 \tValidation Loss: 0.000233 \tvalidation Accuracy: 0.85\n",
      "Epoch: 6 \tTraining Loss: 0.000094 \tTrain Accuracy: 0.76 \tValidation Loss: 0.000228 \tvalidation Accuracy: 0.86\n",
      "Epoch: 7 \tTraining Loss: 0.000090 \tTrain Accuracy: 0.77 \tValidation Loss: 0.000222 \tvalidation Accuracy: 0.85\n",
      "Epoch: 8 \tTraining Loss: 0.000088 \tTrain Accuracy: 0.78 \tValidation Loss: 0.000220 \tvalidation Accuracy: 0.86\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 4931<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/kaggle/working/wandb/run-20210411_121808-nlwcylj8/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/kaggle/working/wandb/run-20210411_121808-nlwcylj8/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>8</td></tr><tr><td>train loss</td><td>9e-05</td></tr><tr><td>train accuracy</td><td>0.77672</td></tr><tr><td>val loss</td><td>0.00022</td></tr><tr><td>val accuracy</td><td>0.8595</td></tr><tr><td>_runtime</td><td>2503</td></tr><tr><td>_timestamp</td><td>1618145991</td></tr><tr><td>_step</td><td>7</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>train loss</td><td>█▄▃▂▂▁▁▁</td></tr><tr><td>train accuracy</td><td>▁▅▆▇▇███</td></tr><tr><td>val loss</td><td>█▅▃▂▂▁▁▁</td></tr><tr><td>val accuracy</td><td>▁▄▆▇▇█▇█</td></tr><tr><td>_runtime</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>_timestamp</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>_step</td><td>▁▂▃▄▅▆▇█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">deft-sweep-3</strong>: <a href=\"https://wandb.ai/rayanz/All_Models_Sweep_1/runs/nlwcylj8\" target=\"_blank\">https://wandb.ai/rayanz/All_Models_Sweep_1/runs/nlwcylj8</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gtcxwbaw with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchnorm_pretrain: YES\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfineTune_epochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate_1: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate_2: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_name: InceptionResNetV2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpreTrain_epochs: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.25<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">dutiful-sweep-4</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/rayanz/All_Models_Sweep_1\" target=\"_blank\">https://wandb.ai/rayanz/All_Models_Sweep_1</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/rayanz/All_Models_Sweep_1/sweeps/f6ktmkwp\" target=\"_blank\">https://wandb.ai/rayanz/All_Models_Sweep_1/sweeps/f6ktmkwp</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/rayanz/All_Models_Sweep_1/runs/gtcxwbaw\" target=\"_blank\">https://wandb.ai/rayanz/All_Models_Sweep_1/runs/gtcxwbaw</a><br/>\n",
       "                Run data is saved locally in <code>/kaggle/working/wandb/run-20210411_130025-gtcxwbaw</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"http://data.lip6.fr/cadene/pretrainedmodels/inceptionresnetv2-520b38e4.pth\" to /root/.cache/torch/hub/checkpoints/inceptionresnetv2-520b38e4.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dade3357b984f3f843763dfc752ee84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/213M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.000193 \tTrain Accuracy: 0.50 \tValidation Loss: 0.000686 \tvalidation Accuracy: 0.74\n",
      "Epoch: 2 \tTraining Loss: 0.000136 \tTrain Accuracy: 0.66 \tValidation Loss: 0.001513 \tvalidation Accuracy: 0.74\n",
      "Epoch: 3 \tTraining Loss: 0.000125 \tTrain Accuracy: 0.69 \tValidation Loss: 0.001092 \tvalidation Accuracy: 0.78\n",
      "Epoch: 4 \tTraining Loss: 0.000109 \tTrain Accuracy: 0.73 \tValidation Loss: 0.005183 \tvalidation Accuracy: 0.73\n",
      "Epoch: 5 \tTraining Loss: 0.000101 \tTrain Accuracy: 0.74 \tValidation Loss: 0.009558 \tvalidation Accuracy: 0.75\n",
      "Epoch: 6 \tTraining Loss: 0.000095 \tTrain Accuracy: 0.76 \tValidation Loss: 0.006939 \tvalidation Accuracy: 0.75\n",
      "Epoch: 7 \tTraining Loss: 0.000090 \tTrain Accuracy: 0.77 \tValidation Loss: 0.003650 \tvalidation Accuracy: 0.79\n",
      "Epoch: 8 \tTraining Loss: 0.000084 \tTrain Accuracy: 0.79 \tValidation Loss: 0.006844 \tvalidation Accuracy: 0.75\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 6509<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/kaggle/working/wandb/run-20210411_130025-gtcxwbaw/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/kaggle/working/wandb/run-20210411_130025-gtcxwbaw/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>8</td></tr><tr><td>train loss</td><td>8e-05</td></tr><tr><td>train accuracy</td><td>0.7901</td></tr><tr><td>val loss</td><td>0.00684</td></tr><tr><td>val accuracy</td><td>0.748</td></tr><tr><td>_runtime</td><td>5656</td></tr><tr><td>_timestamp</td><td>1618151681</td></tr><tr><td>_step</td><td>7</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>train loss</td><td>█▄▄▃▂▂▁▁</td></tr><tr><td>train accuracy</td><td>▁▅▅▆▇▇▇█</td></tr><tr><td>val loss</td><td>▁▂▁▅█▆▃▆</td></tr><tr><td>val accuracy</td><td>▃▂▇▁▄▄█▃</td></tr><tr><td>_runtime</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>_timestamp</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>_step</td><td>▁▂▃▄▅▆▇█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">dutiful-sweep-4</strong>: <a href=\"https://wandb.ai/rayanz/All_Models_Sweep_1/runs/gtcxwbaw\" target=\"_blank\">https://wandb.ai/rayanz/All_Models_Sweep_1/runs/gtcxwbaw</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Exiting.\n"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id, sp_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
