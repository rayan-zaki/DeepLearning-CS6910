{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelName = 'ResNet50'\n",
    "#modelName = 'Vgg16'\n",
    "#modelName = 'InceptionV3'\n",
    "#modelName = 'InceptionResNetV2'\n",
    "modelName = 'Xception'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_val  val\n"
     ]
    }
   ],
   "source": [
    "!ls '/kaggle/input/inaturalist/inaturalist_12K'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xception.py\n"
     ]
    }
   ],
   "source": [
    "!ls '/kaggle/input/xception/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import RandomResizedCrop, RandomHorizontalFlip, Resize, CenterCrop, ToTensor, Normalize, Compose\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import shutil\n",
    "import sys\n",
    "sys.path.append('/kaggle/input/xception/')\n",
    "from xception import*\n",
    "from inceptionresnetv2 import*\n",
    "\n",
    "## Dataset info\n",
    "iNaturalist = {\n",
    "    'Normalize': {\n",
    "        'mean': (0.485, 0.456, 0.406),\n",
    "        'std':  (0.229, 0.224, 0.225)\n",
    "    }\n",
    "}\n",
    "\n",
    "## Dataloaders\n",
    "def data_loader(train_data, val_data, test_data, batchSize):\n",
    "    train_dataLoader = torch.utils.data.DataLoader(train_data, batch_size=batchSize, shuffle=True)\n",
    "    val_dataLoader = torch.utils.data.DataLoader(val_data, batch_size=batchSize, shuffle=True)\n",
    "    test_dataLoader = torch.utils.data.DataLoader(test_data, batch_size=batchSize, shuffle=False)\n",
    "    loaders = {\n",
    "        'train' : train_dataLoader,\n",
    "        'valid' : val_dataLoader,\n",
    "        'test'  : test_dataLoader\n",
    "    }\n",
    "    return loaders\n",
    "\n",
    "## getModdel fn\n",
    "def getModel(modelName):\n",
    "    import torchvision as tv \n",
    "    model = None\n",
    "    \n",
    "    if modelName == 'InceptionV3':\n",
    "        model = tv.models.inception_v3(pretrained=True)\n",
    "    elif modelName == 'InceptionResNetV2':\n",
    "        model = inceptionresnetv2(pretrained='imagenet')\n",
    "    elif modelName == 'ResNet50':\n",
    "        model = tv.models.resnet50(pretrained=True)\n",
    "    elif modelName == 'Xception':\n",
    "        model = xception(pretrained=True)\n",
    "    elif modelName == 'Vgg16':\n",
    "        model = tv.models.vgg16(pretrained=True)\n",
    "        \n",
    "    return model\n",
    "\n",
    "## transforms to match model input dims\n",
    "def transform(modelName):\n",
    "    if modelName == 'Xception' or modelName == 'InceptionV3' or modelName == 'InceptionResNetV2':\n",
    "        resize = 299\n",
    "        val_resize = 333\n",
    "        val_center_crop = resize\n",
    "        \n",
    "    \n",
    "    else:\n",
    "        resize = 224\n",
    "        val_resize = 256\n",
    "        val_center_crop = resize\n",
    "    \n",
    "    \n",
    "    train_t = Compose([RandomResizedCrop(resize),\n",
    "                       RandomHorizontalFlip(),\n",
    "                       ToTensor(),\n",
    "                       Normalize(**iNaturalist['Normalize'])])\n",
    "    valid_t = Compose([Resize(val_resize),\n",
    "                       CenterCrop(resize),\n",
    "                       ToTensor(),\n",
    "                       Normalize(**iNaturalist['Normalize'])])\n",
    "    test_t = Compose([Resize((resize,resize)), \n",
    "                      ToTensor(), \n",
    "                      Normalize(**iNaturalist['Normalize'])])\n",
    "    \n",
    "    transforms = {\n",
    "        'training':   train_t,\n",
    "        'validation': valid_t,\n",
    "        'test': test_t\n",
    "    }\n",
    "    \n",
    "    return transforms\n",
    "\n",
    "## Load dataset fn\n",
    "def load_datasets(modelName):\n",
    "    transforms=transform(modelName)\n",
    "    trainset  = torchvision.datasets.ImageFolder('/kaggle/input/inaturalist/inaturalist_12K/train_val/train', transforms['training'])\n",
    "    valset    = torchvision.datasets.ImageFolder('/kaggle/input/inaturalist/inaturalist_12K/train_val/val', transforms['validation'])\n",
    "    testset   = torchvision.datasets.ImageFolder('/kaggle/input/inaturalist/inaturalist_12K/val', transforms['test'])\n",
    "    \n",
    "    return trainset, valset, testset\n",
    "\n",
    "## Save chkpt\n",
    "def save_ckp(state, is_best, checkpoint_path, best_model_path):\n",
    "    \"\"\"\n",
    "    state: checkpoint we want to save\n",
    "    is_best: is this the best checkpoint; min validation loss\n",
    "    checkpoint_path: path to save checkpoint\n",
    "    best_model_path: path to save best model\n",
    "    \"\"\"\n",
    "    f_path = checkpoint_path\n",
    "    # save checkpoint data to the path given, checkpoint_path\n",
    "    torch.save(state, f_path)\n",
    "    # if it is a best model, min validation loss\n",
    "    if is_best:\n",
    "        best_fpath = best_model_path\n",
    "        # copy that checkpoint file to best path given, best_model_path\n",
    "        shutil.copyfile(f_path, best_fpath)\n",
    "\n",
    "\n",
    "## load chkpt\n",
    "def load_ckp(checkpoint_fpath, model, optimizer):\n",
    "    \"\"\"\n",
    "    checkpoint_path: path to save checkpoint\n",
    "    model: model that we want to load checkpoint parameters into       \n",
    "    optimizer: optimizer we defined in previous training\n",
    "    \"\"\"\n",
    "    # load check point\n",
    "    checkpoint = torch.load(checkpoint_fpath)\n",
    "    # initialize state_dict from checkpoint to model\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    # initialize optimizer from checkpoint to optimizer\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    # initialize valid_loss from checkpoint to valid_loss\n",
    "    valid_loss = checkpoint['valid_loss']\n",
    "    # initialize valid_acc from checkpoint to valid_acc\n",
    "    valid_acc = checkpoint['valid_acc']\n",
    "    # initialize valid_loss from checkpoint to valid_loss\n",
    "    valid_loss_min = checkpoint['valid_loss_min']\n",
    "    # return model, optimizer, epoch value, min validation loss \n",
    "    return model, optimizer, checkpoint['epoch'], valid_loss.item(), valid_acc, valid_loss_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.7/site-packages (0.10.23)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (5.8.0)\n",
      "Requirement already satisfied: configparser>=3.8.1 in /opt/conda/lib/python3.7/site-packages (from wandb) (5.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (2.25.1)\n",
      "Requirement already satisfied: pathtools in /opt/conda/lib/python3.7/site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (3.15.6)\n",
      "Requirement already satisfied: sentry-sdk>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.0.0)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (3.1.13)\n",
      "Requirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.15.0)\n",
      "Requirement already satisfied: Click>=7.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (7.1.2)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.7/site-packages (from wandb) (5.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from wandb) (2.8.1)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.0.1)\n",
      "Requirement already satisfied: subprocess32>=3.5.3 in /opt/conda/lib/python3.7/site-packages (from wandb) (3.5.4)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.7/site-packages (from GitPython>=1.0.0->wandb) (4.0.5)\n",
      "Requirement already satisfied: smmap<4,>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (3.0.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.26.3)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.7/site-packages (0.10.23)\n",
      "Collecting wandb\n",
      "  Downloading wandb-0.10.25-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 865 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (2.25.1)\n",
      "Requirement already satisfied: subprocess32>=3.5.3 in /opt/conda/lib/python3.7/site-packages (from wandb) (3.5.4)\n",
      "Requirement already satisfied: Click>=7.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (7.1.2)\n",
      "Requirement already satisfied: configparser>=3.8.1 in /opt/conda/lib/python3.7/site-packages (from wandb) (5.0.2)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.7/site-packages (from wandb) (5.3.1)\n",
      "Requirement already satisfied: pathtools in /opt/conda/lib/python3.7/site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (3.15.6)\n",
      "Requirement already satisfied: sentry-sdk>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.0.0)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from wandb) (2.8.1)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (5.8.0)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (3.1.13)\n",
      "Requirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.15.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.7/site-packages (from GitPython>=1.0.0->wandb) (4.0.5)\n",
      "Requirement already satisfied: smmap<4,>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (3.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.26.3)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
      "Installing collected packages: wandb\n",
      "  Attempting uninstall: wandb\n",
      "    Found existing installation: wandb 0.10.23\n",
      "    Uninstalling wandb-0.10.23:\n",
      "      Successfully uninstalled wandb-0.10.23\n",
      "Successfully installed wandb-0.10.25\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "!pip install wandb\n",
    "!pip install wandb --upgrade\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:  ········································\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if CUDA is available\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda == True:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.25<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">young-wind-1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/rayanz/Xception_Sweep_1\" target=\"_blank\">https://wandb.ai/rayanz/Xception_Sweep_1</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/rayanz/Xception_Sweep_1/runs/jaym3jfu\" target=\"_blank\">https://wandb.ai/rayanz/Xception_Sweep_1/runs/jaym3jfu</a><br/>\n",
       "                Run data is saved locally in <code>/kaggle/working/wandb/run-20210410_054717-jaym3jfu</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1>Run(jaym3jfu)</h1><iframe src=\"https://wandb.ai/rayanz/Xception_Sweep_1/runs/jaym3jfu\" style=\"border:none;width:100%;height:400px\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f683c8b4850>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=modelName+'_Sweep_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.makedirs(modelName+\"/checkpoint\")\n",
    "    os.makedirs(modelName+\"/best_model\")\n",
    "except:\n",
    "    print(\"directory already present\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckp_path = \"./\"+modelName+\"/checkpoint/current_checkpoint.pt\"\n",
    "best_ckp_path = \"./\"+modelName+\"/best_model/best_model.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if modelName =='Xception':\n",
    "    batch_size = 4\n",
    "else: \n",
    "    batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_change_classifier(model):\n",
    "    #modelName = model.name\n",
    "    if modelName == 'InceptionV3':\n",
    "        model.fc = nn.Sequential(nn.Linear(model.fc.in_features,500),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(),\n",
    "                                 nn.Linear(500,10))\n",
    "\n",
    "\n",
    "    if modelName == 'Vgg16':\n",
    "        model.classifier[6] = nn.Sequential(nn.Linear(model.classifier[6].in_features,500),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(),\n",
    "                                 nn.Linear(500,10))\n",
    "\n",
    "\n",
    "    if modelName == 'ResNet50':\n",
    "        model.fc = nn.Sequential(nn.Linear(model.fc.in_features,500),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(),\n",
    "                             nn.Linear(500,10))\n",
    "\n",
    "    if modelName == 'Xception':\n",
    "        model.fc = nn.Sequential(nn.Linear(model.fc.in_features,500),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(),\n",
    "                             nn.Linear(500,10))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(start_epochs, n_epochs, valid_loss_min_input, loaders, model, optimizer, criterion, use_cuda, checkpoint_path, best_model_path):\n",
    "    \n",
    "    valid_loss_min = valid_loss_min_input \n",
    "    \n",
    "    for epoch in range(start_epochs, start_epochs+n_epochs):\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        \n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        tnum_correct = 0\n",
    "        tnum_examples = 0\n",
    "        for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "                \n",
    "            optimizer.zero_grad()\n",
    "            if model.name == 'InceptionV3':\n",
    "                output, aux_output = model(data)\n",
    "                loss1 = criterion(output, target)\n",
    "                loss2 = criterion(aux_output, target)\n",
    "                loss = loss1 + 0.4*loss2\n",
    "                \n",
    "            else:\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "            \n",
    "            correct = torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1],target).view(-1)\n",
    "            tnum_correct += torch.sum(correct).item()\n",
    "            tnum_examples += correct.shape[0]\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
    "        train_acc = tnum_correct / tnum_examples\n",
    "        \n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        model.eval()\n",
    "        num_correct = 0\n",
    "        num_examples = 0\n",
    "        for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
    "            \n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            \n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n",
    "            \n",
    "            correct = torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1],target).view(-1)\n",
    "            num_correct += torch.sum(correct).item()\n",
    "            num_examples += correct.shape[0]\n",
    "            \n",
    "        train_loss = train_loss/len(loaders['train'].dataset)\n",
    "        valid_loss = valid_loss/len(loaders['valid'].dataset)\n",
    "        valid_acc = num_correct / num_examples\n",
    "        \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tTrain Accuracy: {:.2f} \\tValidation Loss: {:.6f} \\tvalidation Accuracy: {:.2f}'.format(\n",
    "            epoch, \n",
    "            train_loss,\n",
    "            train_acc,\n",
    "            valid_loss,\n",
    "            valid_acc\n",
    "            ))\n",
    "        \n",
    "        wandb.log({'epoch': epoch,'train loss': train_loss,'train accuracy': train_acc,\n",
    "                   'val loss': valid_loss, 'val accuracy': valid_acc})\n",
    "        \n",
    "        checkpoint = {\n",
    "            'epoch': epoch + 1,\n",
    "            'valid_loss': valid_loss,\n",
    "            'valid_acc': valid_acc,\n",
    "            'valid_loss_min': valid_loss_min,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }\n",
    "        \n",
    "        save_ckp(checkpoint, False, checkpoint_path, best_model_path)\n",
    "        \n",
    "        if valid_loss <= valid_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,valid_loss))\n",
    "            # save checkpoint as best model\n",
    "            save_ckp(checkpoint, True, checkpoint_path, best_model_path)\n",
    "            valid_loss_min = valid_loss\n",
    "            \n",
    "    # return trained model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sp_train():\n",
    "    config_defaults = {\n",
    "        'model_name':modelName,\n",
    "        'preTrain_epochs': 3,\n",
    "        'fineTune_epochs': 5,\n",
    "        'learning_rate_1': 1e-4,\n",
    "        'learning_rate_2': 1e-4,\n",
    "        'batchnorm_pretrain':'YES',\n",
    "        'optimizer': 'sgd',\n",
    "        'batch_size': batch_size\n",
    "    }\n",
    "    # Initialize a new wandb run\n",
    "    wandb.init(config=config_defaults)\n",
    "    # Config is a variable that holds and saves hyperparameters and inputs\n",
    "    config = wandb.config\n",
    "    run_name=\"pT_ep:[\"+str(config.preTrain_epochs)+\"] fT_ep:[\"+str(config.fineTune_epochs)+\"] lr1:[\"+str(config.learning_rate_1)+\"] lr2:[\"+str(config.learning_rate_2)+\"] op:[\"+config.optimizer+\"] bs:[\"+str(config.batch_size)+\"] BNpT:[\"+config.batchnorm_pretrain+\"]\"\n",
    "    wandb.run.name=run_name\n",
    "    #wandb.init(config=config_defaults, name= run_name)\n",
    "    \n",
    "    model = getModel(modelName)\n",
    "    model.name = modelName\n",
    "    \n",
    "    \n",
    "    datasetTrain, datasetVal, datasetTest = load_datasets(modelName)\n",
    "    \n",
    "    loaders = data_loader(datasetTrain, datasetVal, datasetTest, config.batch_size)\n",
    "    \n",
    "    # Get Batchnorm Layers\n",
    "    msBN = list(filter(lambda m: type(m) == torch.nn.modules.BatchNorm2d, model.modules()))\n",
    "    \n",
    "    # Freezing layer\n",
    "    for param in model.parameters():\n",
    "        if param.requires_grad:\n",
    "            param.requires_grad=False\n",
    "    \n",
    "    model_change_classifier(model)\n",
    "    \n",
    "    # Batchnorm layers unfreeze\n",
    "    if config.batchnorm_pretrain=='YES':\n",
    "        for i, m in enumerate(msBN):\n",
    "            for param in m.parameters():\n",
    "                param.requires_grad= True\n",
    "                \n",
    "    model = model.to(device)\n",
    "    \n",
    "    if config.optimizer=='sgd':\n",
    "        optimizer = optim.SGD(model.parameters(), lr=config.learning_rate_1, momentum = 0.9)\n",
    "    elif config.optimizer=='adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=config.learning_rate_1, betas=(0.9, 0.999))\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    trained_model = train(start_epochs = 1,\n",
    "                      n_epochs = config.preTrain_epochs,\n",
    "                      valid_loss_min_input = np.Inf,\n",
    "                      loaders = loaders,\n",
    "                      model = model,\n",
    "                      optimizer = optimizer,\n",
    "                      criterion = criterion,\n",
    "                      use_cuda = use_cuda,\n",
    "                      checkpoint_path = ckp_path,\n",
    "                      best_model_path = best_ckp_path\n",
    "                     )\n",
    "    \n",
    "    model, optimizer, start_epoch, valid_loss, valid_acc, valid_loss_min = load_ckp(ckp_path, model, optimizer)\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        param.requires_grad = True\n",
    "        \n",
    "    for g in optimizer.param_groups:\n",
    "        g['lr'] = config.learning_rate_2\n",
    "        \n",
    "    trained_model = train(start_epochs = start_epoch,\n",
    "                      n_epochs = config.fineTune_epochs,\n",
    "                      valid_loss_min_input = valid_loss_min,\n",
    "                      loaders = loaders,\n",
    "                      model = model,\n",
    "                      optimizer = optimizer,\n",
    "                      criterion = criterion,\n",
    "                      use_cuda = use_cuda,\n",
    "                      checkpoint_path = ckp_path,\n",
    "                      best_model_path = best_ckp_path\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'grid', \n",
    "    'metric': {\n",
    "      'name': 'val accuracy',\n",
    "      'goal': 'maximize'   \n",
    "    },\n",
    "    'parameters': {\n",
    "        'Model Name': {\n",
    "            'values':[modelName]\n",
    "        },\n",
    "        'preTrain_epochs': {\n",
    "            'values':[3]\n",
    "        },\n",
    "        'fineTune_epochs': {\n",
    "            'values': [5]\n",
    "        },\n",
    "        'learning_rate_1': {\n",
    "            'values':[0.0001, 0.001] \n",
    "        },\n",
    "        'learning_rate_2':{\n",
    "            'values':[0.0001, 0.001]\n",
    "        },\n",
    "        'batchnorm_pretrain':{\n",
    "            'values': ['YES', 'NO']\n",
    "        },\n",
    "        'optimizer': {\n",
    "            'values':['adam','sgd']\n",
    "        },\n",
    "        'batch_size': {\n",
    "            'values':[batch_size]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: mikg9z8b\n",
      "Sweep URL: https://wandb.ai/rayanz/Xception_Sweep_1/sweeps/mikg9z8b\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=modelName+\"_Sweep_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wwsujkya with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tModel Name: Xception\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchnorm_pretrain: YES\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfineTune_epochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate_1: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate_2: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpreTrain_epochs: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.25<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">dutiful-sweep-1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/rayanz/Xception_Sweep_1\" target=\"_blank\">https://wandb.ai/rayanz/Xception_Sweep_1</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/rayanz/Xception_Sweep_1/sweeps/mikg9z8b\" target=\"_blank\">https://wandb.ai/rayanz/Xception_Sweep_1/sweeps/mikg9z8b</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/rayanz/Xception_Sweep_1/runs/wwsujkya\" target=\"_blank\">https://wandb.ai/rayanz/Xception_Sweep_1/runs/wwsujkya</a><br/>\n",
       "                Run data is saved locally in <code>/kaggle/working/wandb/run-20210410_055004-wwsujkya</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.000177 \tTrain Accuracy: 0.57 \tValidation Loss: 0.000319 \tvalidation Accuracy: 0.82\n",
      "Validation loss decreased (inf --> 0.000319).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 0.000125 \tTrain Accuracy: 0.68 \tValidation Loss: 0.000276 \tvalidation Accuracy: 0.83\n",
      "Validation loss decreased (0.000319 --> 0.000276).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 0.000113 \tTrain Accuracy: 0.71 \tValidation Loss: 0.000260 \tvalidation Accuracy: 0.83\n",
      "Validation loss decreased (0.000276 --> 0.000260).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 0.000118 \tTrain Accuracy: 0.70 \tValidation Loss: 0.000279 \tvalidation Accuracy: 0.83\n",
      "Epoch: 5 \tTraining Loss: 0.000100 \tTrain Accuracy: 0.74 \tValidation Loss: 0.000299 \tvalidation Accuracy: 0.83\n",
      "Epoch: 6 \tTraining Loss: 0.000093 \tTrain Accuracy: 0.76 \tValidation Loss: 0.000292 \tvalidation Accuracy: 0.83\n",
      "Epoch: 7 \tTraining Loss: 0.000085 \tTrain Accuracy: 0.78 \tValidation Loss: 0.000315 \tvalidation Accuracy: 0.83\n",
      "Epoch: 8 \tTraining Loss: 0.000082 \tTrain Accuracy: 0.79 \tValidation Loss: 0.000352 \tvalidation Accuracy: 0.82\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 3053<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/kaggle/working/wandb/run-20210410_055004-wwsujkya/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/kaggle/working/wandb/run-20210410_055004-wwsujkya/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>8</td></tr><tr><td>train loss</td><td>8e-05</td></tr><tr><td>train accuracy</td><td>0.79035</td></tr><tr><td>val loss</td><td>0.00035</td></tr><tr><td>val accuracy</td><td>0.8215</td></tr><tr><td>_runtime</td><td>2728</td></tr><tr><td>_timestamp</td><td>1618036532</td></tr><tr><td>_step</td><td>7</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>train loss</td><td>█▄▃▄▂▂▁▁</td></tr><tr><td>train accuracy</td><td>▁▅▆▅▆▇██</td></tr><tr><td>val loss</td><td>▅▂▁▂▄▃▅█</td></tr><tr><td>val accuracy</td><td>▁▅█▅▇▆▅▃</td></tr><tr><td>_runtime</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>_timestamp</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>_step</td><td>▁▂▃▄▅▆▇█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">dutiful-sweep-1</strong>: <a href=\"https://wandb.ai/rayanz/Xception_Sweep_1/runs/wwsujkya\" target=\"_blank\">https://wandb.ai/rayanz/Xception_Sweep_1/runs/wwsujkya</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wa2i4dit with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tModel Name: Xception\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchnorm_pretrain: YES\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfineTune_epochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate_1: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate_2: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpreTrain_epochs: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.25<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">light-sweep-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/rayanz/Xception_Sweep_1\" target=\"_blank\">https://wandb.ai/rayanz/Xception_Sweep_1</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/rayanz/Xception_Sweep_1/sweeps/mikg9z8b\" target=\"_blank\">https://wandb.ai/rayanz/Xception_Sweep_1/sweeps/mikg9z8b</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/rayanz/Xception_Sweep_1/runs/wa2i4dit\" target=\"_blank\">https://wandb.ai/rayanz/Xception_Sweep_1/runs/wa2i4dit</a><br/>\n",
       "                Run data is saved locally in <code>/kaggle/working/wandb/run-20210410_063539-wa2i4dit</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.000281 \tTrain Accuracy: 0.28 \tValidation Loss: 0.001083 \tvalidation Accuracy: 0.66\n",
      "Validation loss decreased (inf --> 0.001083).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 0.000262 \tTrain Accuracy: 0.49 \tValidation Loss: 0.000958 \tvalidation Accuracy: 0.74\n",
      "Validation loss decreased (0.001083 --> 0.000958).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 0.000233 \tTrain Accuracy: 0.56 \tValidation Loss: 0.000770 \tvalidation Accuracy: 0.76\n",
      "Validation loss decreased (0.000958 --> 0.000770).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 0.000187 \tTrain Accuracy: 0.61 \tValidation Loss: 0.000474 \tvalidation Accuracy: 0.80\n",
      "Validation loss decreased (0.000958 --> 0.000474).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 0.000150 \tTrain Accuracy: 0.64 \tValidation Loss: 0.000341 \tvalidation Accuracy: 0.81\n",
      "Validation loss decreased (0.000474 --> 0.000341).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 0.000133 \tTrain Accuracy: 0.68 \tValidation Loss: 0.000295 \tvalidation Accuracy: 0.82\n",
      "Validation loss decreased (0.000341 --> 0.000295).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 0.000122 \tTrain Accuracy: 0.70 \tValidation Loss: 0.000273 \tvalidation Accuracy: 0.83\n",
      "Validation loss decreased (0.000295 --> 0.000273).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 0.000115 \tTrain Accuracy: 0.71 \tValidation Loss: 0.000261 \tvalidation Accuracy: 0.84\n",
      "Validation loss decreased (0.000273 --> 0.000261).  Saving model ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 4779<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/kaggle/working/wandb/run-20210410_063539-wa2i4dit/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/kaggle/working/wandb/run-20210410_063539-wa2i4dit/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>8</td></tr><tr><td>train loss</td><td>0.00012</td></tr><tr><td>train accuracy</td><td>0.71146</td></tr><tr><td>val loss</td><td>0.00026</td></tr><tr><td>val accuracy</td><td>0.838</td></tr><tr><td>_runtime</td><td>2202</td></tr><tr><td>_timestamp</td><td>1618038741</td></tr><tr><td>_step</td><td>7</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>train loss</td><td>█▇▆▄▂▂▁▁</td></tr><tr><td>train accuracy</td><td>▁▄▆▆▇▇██</td></tr><tr><td>val loss</td><td>█▇▅▃▂▁▁▁</td></tr><tr><td>val accuracy</td><td>▁▄▅▇▇▇██</td></tr><tr><td>_runtime</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>_timestamp</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>_step</td><td>▁▂▃▄▅▆▇█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">light-sweep-2</strong>: <a href=\"https://wandb.ai/rayanz/Xception_Sweep_1/runs/wa2i4dit\" target=\"_blank\">https://wandb.ai/rayanz/Xception_Sweep_1/runs/wa2i4dit</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zzjkiwh0 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tModel Name: Xception\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchnorm_pretrain: YES\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfineTune_epochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate_1: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate_2: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpreTrain_epochs: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.25<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">giddy-sweep-3</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/rayanz/Xception_Sweep_1\" target=\"_blank\">https://wandb.ai/rayanz/Xception_Sweep_1</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/rayanz/Xception_Sweep_1/sweeps/mikg9z8b\" target=\"_blank\">https://wandb.ai/rayanz/Xception_Sweep_1/sweeps/mikg9z8b</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/rayanz/Xception_Sweep_1/runs/zzjkiwh0\" target=\"_blank\">https://wandb.ai/rayanz/Xception_Sweep_1/runs/zzjkiwh0</a><br/>\n",
       "                Run data is saved locally in <code>/kaggle/working/wandb/run-20210410_071235-zzjkiwh0</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.000176 \tTrain Accuracy: 0.58 \tValidation Loss: 0.000309 \tvalidation Accuracy: 0.82\n",
      "Validation loss decreased (inf --> 0.000309).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 0.000128 \tTrain Accuracy: 0.68 \tValidation Loss: 0.000277 \tvalidation Accuracy: 0.82\n",
      "Validation loss decreased (0.000309 --> 0.000277).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 0.000113 \tTrain Accuracy: 0.71 \tValidation Loss: 0.000258 \tvalidation Accuracy: 0.84\n",
      "Validation loss decreased (0.000277 --> 0.000258).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 0.000285 \tTrain Accuracy: 0.14 \tValidation Loss: 0.001191 \tvalidation Accuracy: 0.16\n",
      "Epoch: 5 \tTraining Loss: 0.000284 \tTrain Accuracy: 0.15 \tValidation Loss: 0.001400 \tvalidation Accuracy: 0.18\n",
      "Epoch: 6 \tTraining Loss: 0.000280 \tTrain Accuracy: 0.17 \tValidation Loss: 0.001574 \tvalidation Accuracy: 0.19\n",
      "Epoch: 7 \tTraining Loss: 0.000278 \tTrain Accuracy: 0.18 \tValidation Loss: 0.001660 \tvalidation Accuracy: 0.21\n",
      "Epoch: 8 \tTraining Loss: 0.000275 \tTrain Accuracy: 0.18 \tValidation Loss: 0.001072 \tvalidation Accuracy: 0.19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 6186<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/kaggle/working/wandb/run-20210410_071235-zzjkiwh0/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/kaggle/working/wandb/run-20210410_071235-zzjkiwh0/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>8</td></tr><tr><td>train loss</td><td>0.00027</td></tr><tr><td>train accuracy</td><td>0.18415</td></tr><tr><td>val loss</td><td>0.00107</td></tr><tr><td>val accuracy</td><td>0.187</td></tr><tr><td>_runtime</td><td>2672</td></tr><tr><td>_timestamp</td><td>1618041427</td></tr><tr><td>_step</td><td>7</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>train loss</td><td>▄▂▁█████</td></tr><tr><td>train accuracy</td><td>▆██▁▁▁▁▂</td></tr><tr><td>val loss</td><td>▁▁▁▆▇██▅</td></tr><tr><td>val accuracy</td><td>███▁▁▁▁▁</td></tr><tr><td>_runtime</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>_timestamp</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>_step</td><td>▁▂▃▄▅▆▇█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">giddy-sweep-3</strong>: <a href=\"https://wandb.ai/rayanz/Xception_Sweep_1/runs/zzjkiwh0\" target=\"_blank\">https://wandb.ai/rayanz/Xception_Sweep_1/runs/zzjkiwh0</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rmctk9qa with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tModel Name: Xception\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchnorm_pretrain: YES\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfineTune_epochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate_1: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate_2: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpreTrain_epochs: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.25<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">grateful-sweep-4</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/rayanz/Xception_Sweep_1\" target=\"_blank\">https://wandb.ai/rayanz/Xception_Sweep_1</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/rayanz/Xception_Sweep_1/sweeps/mikg9z8b\" target=\"_blank\">https://wandb.ai/rayanz/Xception_Sweep_1/sweeps/mikg9z8b</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/rayanz/Xception_Sweep_1/runs/rmctk9qa\" target=\"_blank\">https://wandb.ai/rayanz/Xception_Sweep_1/runs/rmctk9qa</a><br/>\n",
       "                Run data is saved locally in <code>/kaggle/working/wandb/run-20210410_075712-rmctk9qa</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.000282 \tTrain Accuracy: 0.26 \tValidation Loss: 0.001081 \tvalidation Accuracy: 0.65\n",
      "Validation loss decreased (inf --> 0.001081).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 0.000262 \tTrain Accuracy: 0.50 \tValidation Loss: 0.000959 \tvalidation Accuracy: 0.75\n",
      "Validation loss decreased (0.001081 --> 0.000959).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 0.000232 \tTrain Accuracy: 0.56 \tValidation Loss: 0.000772 \tvalidation Accuracy: 0.77\n",
      "Validation loss decreased (0.000959 --> 0.000772).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 0.000137 \tTrain Accuracy: 0.66 \tValidation Loss: 0.000247 \tvalidation Accuracy: 0.85\n",
      "Validation loss decreased (0.000959 --> 0.000247).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 0.000104 \tTrain Accuracy: 0.73 \tValidation Loss: 0.000278 \tvalidation Accuracy: 0.82\n",
      "Epoch: 6 \tTraining Loss: 0.000091 \tTrain Accuracy: 0.76 \tValidation Loss: 0.000269 \tvalidation Accuracy: 0.83\n",
      "Epoch: 7 \tTraining Loss: 0.000082 \tTrain Accuracy: 0.79 \tValidation Loss: 0.000259 \tvalidation Accuracy: 0.85\n",
      "Epoch: 8 \tTraining Loss: 0.000078 \tTrain Accuracy: 0.80 \tValidation Loss: 0.000257 \tvalidation Accuracy: 0.85\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 7862<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/kaggle/working/wandb/run-20210410_075712-rmctk9qa/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/kaggle/working/wandb/run-20210410_075712-rmctk9qa/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>8</td></tr><tr><td>train loss</td><td>8e-05</td></tr><tr><td>train accuracy</td><td>0.7996</td></tr><tr><td>val loss</td><td>0.00026</td></tr><tr><td>val accuracy</td><td>0.8475</td></tr><tr><td>_runtime</td><td>2180</td></tr><tr><td>_timestamp</td><td>1618043612</td></tr><tr><td>_step</td><td>7</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>train loss</td><td>█▇▆▃▂▁▁▁</td></tr><tr><td>train accuracy</td><td>▁▄▅▆▇███</td></tr><tr><td>val loss</td><td>█▇▅▁▁▁▁▁</td></tr><tr><td>val accuracy</td><td>▁▄▅█▇▇██</td></tr><tr><td>_runtime</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>_timestamp</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>_step</td><td>▁▂▃▄▅▆▇█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">grateful-sweep-4</strong>: <a href=\"https://wandb.ai/rayanz/Xception_Sweep_1/runs/rmctk9qa\" target=\"_blank\">https://wandb.ai/rayanz/Xception_Sweep_1/runs/rmctk9qa</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: y7ej6lle with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tModel Name: Xception\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchnorm_pretrain: YES\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfineTune_epochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate_1: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate_2: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpreTrain_epochs: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.25<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">super-sweep-5</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/rayanz/Xception_Sweep_1\" target=\"_blank\">https://wandb.ai/rayanz/Xception_Sweep_1</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/rayanz/Xception_Sweep_1/sweeps/mikg9z8b\" target=\"_blank\">https://wandb.ai/rayanz/Xception_Sweep_1/sweeps/mikg9z8b</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/rayanz/Xception_Sweep_1/runs/y7ej6lle\" target=\"_blank\">https://wandb.ai/rayanz/Xception_Sweep_1/runs/y7ej6lle</a><br/>\n",
       "                Run data is saved locally in <code>/kaggle/working/wandb/run-20210410_083355-y7ej6lle</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.000146 \tTrain Accuracy: 0.62 \tValidation Loss: 0.000281 \tvalidation Accuracy: 0.82\n",
      "Validation loss decreased (inf --> 0.000281).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 0.000109 \tTrain Accuracy: 0.72 \tValidation Loss: 0.000242 \tvalidation Accuracy: 0.85\n",
      "Validation loss decreased (0.000281 --> 0.000242).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 0.000100 \tTrain Accuracy: 0.74 \tValidation Loss: 0.000262 \tvalidation Accuracy: 0.84\n",
      "Epoch: 4 \tTraining Loss: 0.000114 \tTrain Accuracy: 0.71 \tValidation Loss: 0.000324 \tvalidation Accuracy: 0.82\n",
      "Epoch: 5 \tTraining Loss: 0.000103 \tTrain Accuracy: 0.74 \tValidation Loss: 0.000343 \tvalidation Accuracy: 0.82\n",
      "Epoch: 6 \tTraining Loss: 0.000096 \tTrain Accuracy: 0.75 \tValidation Loss: 0.000375 \tvalidation Accuracy: 0.82\n",
      "Epoch: 7 \tTraining Loss: 0.000091 \tTrain Accuracy: 0.77 \tValidation Loss: 0.000420 \tvalidation Accuracy: 0.82\n",
      "Epoch: 8 \tTraining Loss: 0.000090 \tTrain Accuracy: 0.77 \tValidation Loss: 0.000396 \tvalidation Accuracy: 0.82\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 9268<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/kaggle/working/wandb/run-20210410_083355-y7ej6lle/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/kaggle/working/wandb/run-20210410_083355-y7ej6lle/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>8</td></tr><tr><td>train loss</td><td>9e-05</td></tr><tr><td>train accuracy</td><td>0.77397</td></tr><tr><td>val loss</td><td>0.0004</td></tr><tr><td>val accuracy</td><td>0.817</td></tr><tr><td>_runtime</td><td>2669</td></tr><tr><td>_timestamp</td><td>1618046304</td></tr><tr><td>_step</td><td>7</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>train loss</td><td>█▃▂▄▃▂▁▁</td></tr><tr><td>train accuracy</td><td>▁▅▇▅▆▇██</td></tr><tr><td>val loss</td><td>▃▁▂▄▅▆█▇</td></tr><tr><td>val accuracy</td><td>▁█▇▂▁▁▂▁</td></tr><tr><td>_runtime</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>_timestamp</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>_step</td><td>▁▂▃▄▅▆▇█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">super-sweep-5</strong>: <a href=\"https://wandb.ai/rayanz/Xception_Sweep_1/runs/y7ej6lle\" target=\"_blank\">https://wandb.ai/rayanz/Xception_Sweep_1/runs/y7ej6lle</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9iwzxg08 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tModel Name: Xception\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchnorm_pretrain: YES\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfineTune_epochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate_1: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate_2: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpreTrain_epochs: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.25<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">eternal-sweep-6</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/rayanz/Xception_Sweep_1\" target=\"_blank\">https://wandb.ai/rayanz/Xception_Sweep_1</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/rayanz/Xception_Sweep_1/sweeps/mikg9z8b\" target=\"_blank\">https://wandb.ai/rayanz/Xception_Sweep_1/sweeps/mikg9z8b</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/rayanz/Xception_Sweep_1/runs/9iwzxg08\" target=\"_blank\">https://wandb.ai/rayanz/Xception_Sweep_1/runs/9iwzxg08</a><br/>\n",
       "                Run data is saved locally in <code>/kaggle/working/wandb/run-20210410_091828-9iwzxg08</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.000194 \tTrain Accuracy: 0.52 \tValidation Loss: 0.000337 \tvalidation Accuracy: 0.81\n",
      "Validation loss decreased (inf --> 0.000337).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 0.000127 \tTrain Accuracy: 0.68 \tValidation Loss: 0.000276 \tvalidation Accuracy: 0.82\n",
      "Validation loss decreased (0.000337 --> 0.000276).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 0.000114 \tTrain Accuracy: 0.71 \tValidation Loss: 0.000260 \tvalidation Accuracy: 0.84\n",
      "Validation loss decreased (0.000276 --> 0.000260).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 0.000106 \tTrain Accuracy: 0.73 \tValidation Loss: 0.000242 \tvalidation Accuracy: 0.85\n",
      "Validation loss decreased (0.000276 --> 0.000242).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 0.000100 \tTrain Accuracy: 0.75 \tValidation Loss: 0.000236 \tvalidation Accuracy: 0.86\n",
      "Validation loss decreased (0.000242 --> 0.000236).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 0.000094 \tTrain Accuracy: 0.76 \tValidation Loss: 0.000232 \tvalidation Accuracy: 0.86\n",
      "Validation loss decreased (0.000236 --> 0.000232).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 0.000093 \tTrain Accuracy: 0.76 \tValidation Loss: 0.000229 \tvalidation Accuracy: 0.86\n",
      "Validation loss decreased (0.000232 --> 0.000229).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 0.000087 \tTrain Accuracy: 0.78 \tValidation Loss: 0.000225 \tvalidation Accuracy: 0.86\n",
      "Validation loss decreased (0.000229 --> 0.000225).  Saving model ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 10998<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/kaggle/working/wandb/run-20210410_091828-9iwzxg08/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/kaggle/working/wandb/run-20210410_091828-9iwzxg08/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>8</td></tr><tr><td>train loss</td><td>9e-05</td></tr><tr><td>train accuracy</td><td>0.77585</td></tr><tr><td>val loss</td><td>0.00022</td></tr><tr><td>val accuracy</td><td>0.865</td></tr><tr><td>_runtime</td><td>2190</td></tr><tr><td>_timestamp</td><td>1618048498</td></tr><tr><td>_step</td><td>7</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>train loss</td><td>█▄▃▂▂▁▁▁</td></tr><tr><td>train accuracy</td><td>▁▅▆▇▇███</td></tr><tr><td>val loss</td><td>█▄▃▂▂▁▁▁</td></tr><tr><td>val accuracy</td><td>▁▃▅▇▇▇██</td></tr><tr><td>_runtime</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>_timestamp</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>_step</td><td>▁▂▃▄▅▆▇█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">eternal-sweep-6</strong>: <a href=\"https://wandb.ai/rayanz/Xception_Sweep_1/runs/9iwzxg08\" target=\"_blank\">https://wandb.ai/rayanz/Xception_Sweep_1/runs/9iwzxg08</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: tz4inxku with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tModel Name: Xception\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchnorm_pretrain: YES\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfineTune_epochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate_1: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate_2: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpreTrain_epochs: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.25<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">breezy-sweep-7</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/rayanz/Xception_Sweep_1\" target=\"_blank\">https://wandb.ai/rayanz/Xception_Sweep_1</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/rayanz/Xception_Sweep_1/sweeps/mikg9z8b\" target=\"_blank\">https://wandb.ai/rayanz/Xception_Sweep_1/sweeps/mikg9z8b</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/rayanz/Xception_Sweep_1/runs/tz4inxku\" target=\"_blank\">https://wandb.ai/rayanz/Xception_Sweep_1/runs/tz4inxku</a><br/>\n",
       "                Run data is saved locally in <code>/kaggle/working/wandb/run-20210410_095502-tz4inxku</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.000145 \tTrain Accuracy: 0.62 \tValidation Loss: 0.000292 \tvalidation Accuracy: 0.81\n",
      "Validation loss decreased (inf --> 0.000292).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 0.000112 \tTrain Accuracy: 0.71 \tValidation Loss: 0.000255 \tvalidation Accuracy: 0.83\n",
      "Validation loss decreased (0.000292 --> 0.000255).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 0.000101 \tTrain Accuracy: 0.74 \tValidation Loss: 0.000242 \tvalidation Accuracy: 0.86\n",
      "Validation loss decreased (0.000255 --> 0.000242).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 0.000283 \tTrain Accuracy: 0.16 \tValidation Loss: 0.001117 \tvalidation Accuracy: 0.20\n",
      "Epoch: 5 \tTraining Loss: 0.000283 \tTrain Accuracy: 0.15 \tValidation Loss: 0.001491 \tvalidation Accuracy: 0.14\n",
      "Epoch: 6 \tTraining Loss: 0.000283 \tTrain Accuracy: 0.15 \tValidation Loss: 0.001131 \tvalidation Accuracy: 0.18\n",
      "Epoch: 7 \tTraining Loss: 0.000281 \tTrain Accuracy: 0.16 \tValidation Loss: 0.001159 \tvalidation Accuracy: 0.21\n",
      "Epoch: 8 \tTraining Loss: 0.000277 \tTrain Accuracy: 0.18 \tValidation Loss: 0.001352 \tvalidation Accuracy: 0.19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 12370<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/kaggle/working/wandb/run-20210410_095502-tz4inxku/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/kaggle/working/wandb/run-20210410_095502-tz4inxku/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>8</td></tr><tr><td>train loss</td><td>0.00028</td></tr><tr><td>train accuracy</td><td>0.17702</td></tr><tr><td>val loss</td><td>0.00135</td></tr><tr><td>val accuracy</td><td>0.189</td></tr><tr><td>_runtime</td><td>2694</td></tr><tr><td>_timestamp</td><td>1618051196</td></tr><tr><td>_step</td><td>7</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>train loss</td><td>▃▁▁█████</td></tr><tr><td>train accuracy</td><td>▇██▁▁▁▁▁</td></tr><tr><td>val loss</td><td>▁▁▁▆█▆▆▇</td></tr><tr><td>val accuracy</td><td>▇██▂▁▁▂▁</td></tr><tr><td>_runtime</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>_timestamp</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>_step</td><td>▁▂▃▄▅▆▇█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">breezy-sweep-7</strong>: <a href=\"https://wandb.ai/rayanz/Xception_Sweep_1/runs/tz4inxku\" target=\"_blank\">https://wandb.ai/rayanz/Xception_Sweep_1/runs/tz4inxku</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Error while calling W&B API: Post \"http://anaconda.default.svc.cluster.local/search\": context deadline exceeded (<Response [500]>)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: x52iie9d with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tModel Name: Xception\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchnorm_pretrain: YES\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfineTune_epochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate_1: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate_2: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpreTrain_epochs: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.25<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">woven-sweep-8</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/rayanz/Xception_Sweep_1\" target=\"_blank\">https://wandb.ai/rayanz/Xception_Sweep_1</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/rayanz/Xception_Sweep_1/sweeps/mikg9z8b\" target=\"_blank\">https://wandb.ai/rayanz/Xception_Sweep_1/sweeps/mikg9z8b</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/rayanz/Xception_Sweep_1/runs/x52iie9d\" target=\"_blank\">https://wandb.ai/rayanz/Xception_Sweep_1/runs/x52iie9d</a><br/>\n",
       "                Run data is saved locally in <code>/kaggle/working/wandb/run-20210410_104040-x52iie9d</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.000195 \tTrain Accuracy: 0.52 \tValidation Loss: 0.000342 \tvalidation Accuracy: 0.81\n",
      "Validation loss decreased (inf --> 0.000342).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 0.000125 \tTrain Accuracy: 0.68 \tValidation Loss: 0.000297 \tvalidation Accuracy: 0.82\n",
      "Validation loss decreased (0.000342 --> 0.000297).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 0.000114 \tTrain Accuracy: 0.71 \tValidation Loss: 0.000264 \tvalidation Accuracy: 0.84\n",
      "Validation loss decreased (0.000297 --> 0.000264).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 0.000110 \tTrain Accuracy: 0.72 \tValidation Loss: 0.000266 \tvalidation Accuracy: 0.83\n",
      "Validation loss decreased (0.000297 --> 0.000266).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 0.000097 \tTrain Accuracy: 0.75 \tValidation Loss: 0.000255 \tvalidation Accuracy: 0.85\n",
      "Validation loss decreased (0.000266 --> 0.000255).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 0.000086 \tTrain Accuracy: 0.78 \tValidation Loss: 0.000247 \tvalidation Accuracy: 0.85\n",
      "Validation loss decreased (0.000255 --> 0.000247).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 0.000081 \tTrain Accuracy: 0.79 \tValidation Loss: 0.000272 \tvalidation Accuracy: 0.84\n",
      "Epoch: 8 \tTraining Loss: 0.000076 \tTrain Accuracy: 0.80 \tValidation Loss: 0.000244 \tvalidation Accuracy: 0.86\n",
      "Validation loss decreased (0.000247 --> 0.000244).  Saving model ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 14101<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/kaggle/working/wandb/run-20210410_104040-x52iie9d/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/kaggle/working/wandb/run-20210410_104040-x52iie9d/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>8</td></tr><tr><td>train loss</td><td>8e-05</td></tr><tr><td>train accuracy</td><td>0.8046</td></tr><tr><td>val loss</td><td>0.00024</td></tr><tr><td>val accuracy</td><td>0.8595</td></tr><tr><td>_runtime</td><td>2153</td></tr><tr><td>_timestamp</td><td>1618053393</td></tr><tr><td>_step</td><td>7</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>train loss</td><td>█▄▃▃▂▂▁▁</td></tr><tr><td>train accuracy</td><td>▁▅▆▆▇▇██</td></tr><tr><td>val loss</td><td>█▅▂▃▂▁▃▁</td></tr><tr><td>val accuracy</td><td>▁▃▅▄▆▇▆█</td></tr><tr><td>_runtime</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>_timestamp</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>_step</td><td>▁▂▃▄▅▆▇█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">woven-sweep-8</strong>: <a href=\"https://wandb.ai/rayanz/Xception_Sweep_1/runs/x52iie9d\" target=\"_blank\">https://wandb.ai/rayanz/Xception_Sweep_1/runs/x52iie9d</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qjuqo1oz with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tModel Name: Xception\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchnorm_pretrain: NO\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfineTune_epochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate_1: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate_2: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpreTrain_epochs: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.25<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">soft-sweep-9</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/rayanz/Xception_Sweep_1\" target=\"_blank\">https://wandb.ai/rayanz/Xception_Sweep_1</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/rayanz/Xception_Sweep_1/sweeps/mikg9z8b\" target=\"_blank\">https://wandb.ai/rayanz/Xception_Sweep_1/sweeps/mikg9z8b</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/rayanz/Xception_Sweep_1/runs/qjuqo1oz\" target=\"_blank\">https://wandb.ai/rayanz/Xception_Sweep_1/runs/qjuqo1oz</a><br/>\n",
       "                Run data is saved locally in <code>/kaggle/working/wandb/run-20210410_111638-qjuqo1oz</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.000192 \tTrain Accuracy: 0.53 \tValidation Loss: 0.000400 \tvalidation Accuracy: 0.79\n",
      "Validation loss decreased (inf --> 0.000400).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 0.000140 \tTrain Accuracy: 0.65 \tValidation Loss: 0.000366 \tvalidation Accuracy: 0.79\n",
      "Validation loss decreased (0.000400 --> 0.000366).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 0.000135 \tTrain Accuracy: 0.66 \tValidation Loss: 0.000307 \tvalidation Accuracy: 0.81\n",
      "Validation loss decreased (0.000366 --> 0.000307).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 0.000122 \tTrain Accuracy: 0.69 \tValidation Loss: 0.000295 \tvalidation Accuracy: 0.82\n",
      "Validation loss decreased (0.000366 --> 0.000295).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 0.000104 \tTrain Accuracy: 0.73 \tValidation Loss: 0.000273 \tvalidation Accuracy: 0.83\n",
      "Validation loss decreased (0.000295 --> 0.000273).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 0.000092 \tTrain Accuracy: 0.76 \tValidation Loss: 0.000309 \tvalidation Accuracy: 0.83\n",
      "Epoch: 7 \tTraining Loss: 0.000086 \tTrain Accuracy: 0.78 \tValidation Loss: 0.000327 \tvalidation Accuracy: 0.83\n",
      "Epoch: 8 \tTraining Loss: 0.000083 \tTrain Accuracy: 0.79 \tValidation Loss: 0.000317 \tvalidation Accuracy: 0.83\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 15469<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/kaggle/working/wandb/run-20210410_111638-qjuqo1oz/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/kaggle/working/wandb/run-20210410_111638-qjuqo1oz/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>8</td></tr><tr><td>train loss</td><td>8e-05</td></tr><tr><td>train accuracy</td><td>0.78772</td></tr><tr><td>val loss</td><td>0.00032</td></tr><tr><td>val accuracy</td><td>0.8295</td></tr><tr><td>_runtime</td><td>2497</td></tr><tr><td>_timestamp</td><td>1618055895</td></tr><tr><td>_step</td><td>7</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>train loss</td><td>█▅▄▃▂▂▁▁</td></tr><tr><td>train accuracy</td><td>▁▄▅▅▆▇██</td></tr><tr><td>val loss</td><td>█▆▃▂▁▃▄▃</td></tr><tr><td>val accuracy</td><td>▁▁▅▆▇▇██</td></tr><tr><td>_runtime</td><td>▁▂▂▄▅▆▇█</td></tr><tr><td>_timestamp</td><td>▁▂▂▄▅▆▇█</td></tr><tr><td>_step</td><td>▁▂▃▄▅▆▇█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">soft-sweep-9</strong>: <a href=\"https://wandb.ai/rayanz/Xception_Sweep_1/runs/qjuqo1oz\" target=\"_blank\">https://wandb.ai/rayanz/Xception_Sweep_1/runs/qjuqo1oz</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: azimu8uu with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tModel Name: Xception\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchnorm_pretrain: NO\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfineTune_epochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate_1: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate_2: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpreTrain_epochs: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.25<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">elated-sweep-10</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/rayanz/Xception_Sweep_1\" target=\"_blank\">https://wandb.ai/rayanz/Xception_Sweep_1</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/rayanz/Xception_Sweep_1/sweeps/mikg9z8b\" target=\"_blank\">https://wandb.ai/rayanz/Xception_Sweep_1/sweeps/mikg9z8b</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/rayanz/Xception_Sweep_1/runs/azimu8uu\" target=\"_blank\">https://wandb.ai/rayanz/Xception_Sweep_1/runs/azimu8uu</a><br/>\n",
       "                Run data is saved locally in <code>/kaggle/working/wandb/run-20210410_115829-azimu8uu</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.000281 \tTrain Accuracy: 0.26 \tValidation Loss: 0.001079 \tvalidation Accuracy: 0.67\n",
      "Validation loss decreased (inf --> 0.001079).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 0.000263 \tTrain Accuracy: 0.48 \tValidation Loss: 0.000966 \tvalidation Accuracy: 0.76\n",
      "Validation loss decreased (0.001079 --> 0.000966).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 0.000237 \tTrain Accuracy: 0.56 \tValidation Loss: 0.000812 \tvalidation Accuracy: 0.77\n",
      "Validation loss decreased (0.000966 --> 0.000812).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 0.000192 \tTrain Accuracy: 0.61 \tValidation Loss: 0.000487 \tvalidation Accuracy: 0.80\n",
      "Validation loss decreased (0.000966 --> 0.000487).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 0.000152 \tTrain Accuracy: 0.64 \tValidation Loss: 0.000360 \tvalidation Accuracy: 0.80\n",
      "Validation loss decreased (0.000487 --> 0.000360).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 0.000134 \tTrain Accuracy: 0.67 \tValidation Loss: 0.000304 \tvalidation Accuracy: 0.82\n",
      "Validation loss decreased (0.000360 --> 0.000304).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 0.000122 \tTrain Accuracy: 0.70 \tValidation Loss: 0.000276 \tvalidation Accuracy: 0.83\n",
      "Validation loss decreased (0.000304 --> 0.000276).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 0.000114 \tTrain Accuracy: 0.72 \tValidation Loss: 0.000259 \tvalidation Accuracy: 0.84\n",
      "Validation loss decreased (0.000276 --> 0.000259).  Saving model ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 17077<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/kaggle/working/wandb/run-20210410_115829-azimu8uu/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/kaggle/working/wandb/run-20210410_115829-azimu8uu/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>8</td></tr><tr><td>train loss</td><td>0.00011</td></tr><tr><td>train accuracy</td><td>0.71546</td></tr><tr><td>val loss</td><td>0.00026</td></tr><tr><td>val accuracy</td><td>0.839</td></tr><tr><td>_runtime</td><td>2089</td></tr><tr><td>_timestamp</td><td>1618057998</td></tr><tr><td>_step</td><td>7</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>train loss</td><td>█▇▆▄▃▂▁▁</td></tr><tr><td>train accuracy</td><td>▁▄▆▆▇▇██</td></tr><tr><td>val loss</td><td>█▇▆▃▂▁▁▁</td></tr><tr><td>val accuracy</td><td>▁▅▅▆▆▇██</td></tr><tr><td>_runtime</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>_timestamp</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>_step</td><td>▁▂▃▄▅▆▇█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">elated-sweep-10</strong>: <a href=\"https://wandb.ai/rayanz/Xception_Sweep_1/runs/azimu8uu\" target=\"_blank\">https://wandb.ai/rayanz/Xception_Sweep_1/runs/azimu8uu</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3xwnl26s with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tModel Name: Xception\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchnorm_pretrain: NO\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfineTune_epochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate_1: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate_2: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpreTrain_epochs: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.25<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">true-sweep-11</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/rayanz/Xception_Sweep_1\" target=\"_blank\">https://wandb.ai/rayanz/Xception_Sweep_1</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/rayanz/Xception_Sweep_1/sweeps/mikg9z8b\" target=\"_blank\">https://wandb.ai/rayanz/Xception_Sweep_1/sweeps/mikg9z8b</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/rayanz/Xception_Sweep_1/runs/3xwnl26s\" target=\"_blank\">https://wandb.ai/rayanz/Xception_Sweep_1/runs/3xwnl26s</a><br/>\n",
       "                Run data is saved locally in <code>/kaggle/working/wandb/run-20210410_123337-3xwnl26s</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.000193 \tTrain Accuracy: 0.54 \tValidation Loss: 0.000398 \tvalidation Accuracy: 0.79\n",
      "Validation loss decreased (inf --> 0.000398).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 0.000143 \tTrain Accuracy: 0.65 \tValidation Loss: 0.000333 \tvalidation Accuracy: 0.81\n",
      "Validation loss decreased (0.000398 --> 0.000333).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 0.000134 \tTrain Accuracy: 0.66 \tValidation Loss: 0.000308 \tvalidation Accuracy: 0.81\n",
      "Validation loss decreased (0.000333 --> 0.000308).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 0.000285 \tTrain Accuracy: 0.15 \tValidation Loss: 0.001165 \tvalidation Accuracy: 0.16\n",
      "Epoch: 5 \tTraining Loss: 0.000282 \tTrain Accuracy: 0.16 \tValidation Loss: 0.001387 \tvalidation Accuracy: 0.19\n",
      "Epoch: 6 \tTraining Loss: 0.000279 \tTrain Accuracy: 0.17 \tValidation Loss: 0.001066 \tvalidation Accuracy: 0.24\n",
      "Epoch: 7 \tTraining Loss: 0.000271 \tTrain Accuracy: 0.20 \tValidation Loss: 0.001043 \tvalidation Accuracy: 0.26\n",
      "Epoch: 8 \tTraining Loss: 0.000264 \tTrain Accuracy: 0.22 \tValidation Loss: 0.000984 \tvalidation Accuracy: 0.28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 18408<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/kaggle/working/wandb/run-20210410_123337-3xwnl26s/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/kaggle/working/wandb/run-20210410_123337-3xwnl26s/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>8</td></tr><tr><td>train loss</td><td>0.00026</td></tr><tr><td>train accuracy</td><td>0.22353</td></tr><tr><td>val loss</td><td>0.00098</td></tr><tr><td>val accuracy</td><td>0.281</td></tr><tr><td>_runtime</td><td>2482</td></tr><tr><td>_timestamp</td><td>1618060499</td></tr><tr><td>_step</td><td>7</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>train loss</td><td>▄▁▁███▇▇</td></tr><tr><td>train accuracy</td><td>▆██▁▁▁▂▂</td></tr><tr><td>val loss</td><td>▂▁▁▇█▆▆▅</td></tr><tr><td>val accuracy</td><td>███▁▁▂▂▂</td></tr><tr><td>_runtime</td><td>▁▂▂▄▅▆▇█</td></tr><tr><td>_timestamp</td><td>▁▂▂▄▅▆▇█</td></tr><tr><td>_step</td><td>▁▂▃▄▅▆▇█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">true-sweep-11</strong>: <a href=\"https://wandb.ai/rayanz/Xception_Sweep_1/runs/3xwnl26s\" target=\"_blank\">https://wandb.ai/rayanz/Xception_Sweep_1/runs/3xwnl26s</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: f6uboqz0 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tModel Name: Xception\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchnorm_pretrain: NO\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfineTune_epochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate_1: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate_2: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpreTrain_epochs: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.25<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">distinctive-sweep-12</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/rayanz/Xception_Sweep_1\" target=\"_blank\">https://wandb.ai/rayanz/Xception_Sweep_1</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/rayanz/Xception_Sweep_1/sweeps/mikg9z8b\" target=\"_blank\">https://wandb.ai/rayanz/Xception_Sweep_1/sweeps/mikg9z8b</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/rayanz/Xception_Sweep_1/runs/f6uboqz0\" target=\"_blank\">https://wandb.ai/rayanz/Xception_Sweep_1/runs/f6uboqz0</a><br/>\n",
       "                Run data is saved locally in <code>/kaggle/working/wandb/run-20210410_131504-f6uboqz0</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.000281 \tTrain Accuracy: 0.27 \tValidation Loss: 0.001074 \tvalidation Accuracy: 0.65\n",
      "Validation loss decreased (inf --> 0.001074).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 0.000261 \tTrain Accuracy: 0.49 \tValidation Loss: 0.000955 \tvalidation Accuracy: 0.74\n",
      "Validation loss decreased (0.001074 --> 0.000955).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 0.000234 \tTrain Accuracy: 0.56 \tValidation Loss: 0.000794 \tvalidation Accuracy: 0.77\n",
      "Validation loss decreased (0.000955 --> 0.000794).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 0.000137 \tTrain Accuracy: 0.66 \tValidation Loss: 0.000271 \tvalidation Accuracy: 0.82\n",
      "Validation loss decreased (0.000955 --> 0.000271).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 0.000104 \tTrain Accuracy: 0.74 \tValidation Loss: 0.000248 \tvalidation Accuracy: 0.84\n",
      "Validation loss decreased (0.000271 --> 0.000248).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 0.000090 \tTrain Accuracy: 0.77 \tValidation Loss: 0.000244 \tvalidation Accuracy: 0.85\n",
      "Validation loss decreased (0.000248 --> 0.000244).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 0.000084 \tTrain Accuracy: 0.79 \tValidation Loss: 0.000265 \tvalidation Accuracy: 0.85\n"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id, sp_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: nx5ma5ly with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tModel Name: Xception\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchnorm_pretrain: NO\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfineTune_epochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate_1: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate_2: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpreTrain_epochs: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.25<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">stilted-sweep-16</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/rayanz/Xception_Sweep_1\" target=\"_blank\">https://wandb.ai/rayanz/Xception_Sweep_1</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/rayanz/Xception_Sweep_1/sweeps/mikg9z8b\" target=\"_blank\">https://wandb.ai/rayanz/Xception_Sweep_1/sweeps/mikg9z8b</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/rayanz/Xception_Sweep_1/runs/nx5ma5ly\" target=\"_blank\">https://wandb.ai/rayanz/Xception_Sweep_1/runs/nx5ma5ly</a><br/>\n",
       "                Run data is saved locally in <code>/kaggle/working/wandb/run-20210410_174324-nx5ma5ly</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.000281 \tTrain Accuracy: 0.27 \tValidation Loss: 0.001084 \tvalidation Accuracy: 0.63\n",
      "Validation loss decreased (inf --> 0.001084).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 0.000262 \tTrain Accuracy: 0.49 \tValidation Loss: 0.000959 \tvalidation Accuracy: 0.73\n",
      "Validation loss decreased (0.001084 --> 0.000959).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 0.000235 \tTrain Accuracy: 0.56 \tValidation Loss: 0.000805 \tvalidation Accuracy: 0.75\n",
      "Validation loss decreased (0.000959 --> 0.000805).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 0.000135 \tTrain Accuracy: 0.66 \tValidation Loss: 0.000300 \tvalidation Accuracy: 0.81\n",
      "Validation loss decreased (0.000959 --> 0.000300).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 0.000103 \tTrain Accuracy: 0.74 \tValidation Loss: 0.000253 \tvalidation Accuracy: 0.85\n",
      "Validation loss decreased (0.000300 --> 0.000253).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 0.000093 \tTrain Accuracy: 0.76 \tValidation Loss: 0.000245 \tvalidation Accuracy: 0.85\n",
      "Validation loss decreased (0.000253 --> 0.000245).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 0.000084 \tTrain Accuracy: 0.78 \tValidation Loss: 0.000265 \tvalidation Accuracy: 0.83\n",
      "Epoch: 8 \tTraining Loss: 0.000080 \tTrain Accuracy: 0.79 \tValidation Loss: 0.000238 \tvalidation Accuracy: 0.86\n",
      "Validation loss decreased (0.000245 --> 0.000238).  Saving model ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 5703<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/kaggle/working/wandb/run-20210410_174324-nx5ma5ly/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/kaggle/working/wandb/run-20210410_174324-nx5ma5ly/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>8</td></tr><tr><td>train loss</td><td>8e-05</td></tr><tr><td>train accuracy</td><td>0.78985</td></tr><tr><td>val loss</td><td>0.00024</td></tr><tr><td>val accuracy</td><td>0.856</td></tr><tr><td>_runtime</td><td>1922</td></tr><tr><td>_timestamp</td><td>1618078526</td></tr><tr><td>_step</td><td>7</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>train loss</td><td>█▇▆▃▂▁▁▁</td></tr><tr><td>train accuracy</td><td>▁▄▅▆▇███</td></tr><tr><td>val loss</td><td>█▇▆▂▁▁▁▁</td></tr><tr><td>val accuracy</td><td>▁▄▅▇██▇█</td></tr><tr><td>_runtime</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>_timestamp</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>_step</td><td>▁▂▃▄▅▆▇█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">stilted-sweep-16</strong>: <a href=\"https://wandb.ai/rayanz/Xception_Sweep_1/runs/nx5ma5ly\" target=\"_blank\">https://wandb.ai/rayanz/Xception_Sweep_1/runs/nx5ma5ly</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Exiting.\n"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id = 'mikg9z8b', project = modelName+'_Sweep_1', function = sp_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
